{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_path\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_sched\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "from lib.net.point_rcnn import PointRCNN\n",
    "import lib.net.train_functions as train_functions\n",
    "from lib.datasets.kitti_rcnn_dataset import KittiRCNNDataset\n",
    "from lib.config import cfg, cfg_from_file, save_config_to_file\n",
    "import tools.train_utils.train_utils as train_utils\n",
    "from tools.train_utils.fastai_optim import OptimWrapper\n",
    "from tools.train_utils import learning_schedules_fastai as lsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lingling/anaconda3/envs/pytorch/lib/python3.7/logging/__init__.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getsourcefile(logging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logger(log_file):\n",
    "    log_format = '%(asctime)s  %(levelname)5s  %(message)s'\n",
    "    logging.basicConfig(level=logging.DEBUG, format=log_format, filename=log_file)\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.DEBUG)\n",
    "    console.setFormatter(logging.Formatter(log_format))\n",
    "    logging.getLogger(__name__).addHandler(console)\n",
    "    return logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(logger):\n",
    "    DATA_PATH = os.path.join('../', 'data')\n",
    "\n",
    "    # create dataloader\n",
    "    train_set = KittiRCNNDataset(root_dir=DATA_PATH, npoints=cfg.RPN.NUM_POINTS, split=cfg.TRAIN.SPLIT, mode='TRAIN',\n",
    "                                 logger=logger,\n",
    "                                 classes=cfg.CLASSES,\n",
    "                                 rcnn_training_roi_dir=args.rcnn_training_roi_dir,\n",
    "                                 rcnn_training_feature_dir=args.rcnn_training_feature_dir,\n",
    "                                 gt_database_dir=args.gt_database)\n",
    "    train_loader = DataLoader(train_set, batch_size=args.batch_size, pin_memory=True,\n",
    "                              num_workers=args.workers, shuffle=True, collate_fn=train_set.collate_batch,\n",
    "                              drop_last=True)\n",
    "\n",
    "    if args.train_with_eval:\n",
    "        test_set = KittiRCNNDataset(root_dir=DATA_PATH, npoints=cfg.RPN.NUM_POINTS, split=cfg.TRAIN.VAL_SPLIT, mode='EVAL',\n",
    "                                    logger=logger,\n",
    "                                    classes=cfg.CLASSES,\n",
    "                                    rcnn_eval_roi_dir=args.rcnn_eval_roi_dir,\n",
    "                                    rcnn_eval_feature_dir=args.rcnn_eval_feature_dir)\n",
    "        test_loader = DataLoader(test_set, batch_size=1, shuffle=True, pin_memory=True,\n",
    "                                 num_workers=args.workers, collate_fn=test_set.collate_batch)\n",
    "    else:\n",
    "        test_loader = None\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(model):\n",
    "\n",
    "    if cfg.TRAIN.OPTIMIZER == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=cfg.TRAIN.LR, weight_decay=cfg.TRAIN.WEIGHT_DECAY)\n",
    "    elif cfg.TRAIN.OPTIMIZER == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=cfg.TRAIN.LR, weight_decay=cfg.TRAIN.WEIGHT_DECAY,\n",
    "                              momentum=cfg.TRAIN.MOMENTUM)\n",
    "    elif cfg.TRAIN.OPTIMIZER == 'adam_onecycle':\n",
    "        def children(m: nn.Module):\n",
    "            return list(m.children())\n",
    "\n",
    "        def num_children(m: nn.Module) -> int:\n",
    "            return len(children(m))\n",
    "\n",
    "        flatten_model = lambda m: sum(map(flatten_model, m.children()), []) if num_children(m) else [m]\n",
    "        get_layer_groups = lambda m: [nn.Sequential(*flatten_model(m))]\n",
    "\n",
    "        optimizer_func = partial(optim.Adam, betas=(0.9, 0.99))\n",
    "        optimizer = OptimWrapper.create(\n",
    "            optimizer_func, 3e-3, get_layer_groups(model), wd=cfg.TRAIN.WEIGHT_DECAY, true_wd=True, bn_wd=True\n",
    "        )\n",
    "\n",
    "        # fix rpn: do this since we use costomized optimizer.step\n",
    "        if cfg.RPN.ENABLED and cfg.RPN.FIXED:\n",
    "            for param in model.rpn.parameters():\n",
    "                param.requires_grad = False\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_scheduler(optimizer, total_steps, last_epoch):\n",
    "    def lr_lbmd(cur_epoch):\n",
    "        cur_decay = 1\n",
    "        for decay_step in cfg.TRAIN.DECAY_STEP_LIST:\n",
    "            if cur_epoch >= decay_step:\n",
    "                cur_decay = cur_decay * cfg.TRAIN.LR_DECAY\n",
    "        return max(cur_decay, cfg.TRAIN.LR_CLIP / cfg.TRAIN.LR)\n",
    "\n",
    "    def bnm_lmbd(cur_epoch):\n",
    "        cur_decay = 1\n",
    "        for decay_step in cfg.TRAIN.BN_DECAY_STEP_LIST:\n",
    "            if cur_epoch >= decay_step:\n",
    "                cur_decay = cur_decay * cfg.TRAIN.BN_DECAY\n",
    "        return max(cfg.TRAIN.BN_MOMENTUM * cur_decay, cfg.TRAIN.BNM_CLIP)\n",
    "\n",
    "    if cfg.TRAIN.OPTIMIZER == 'adam_onecycle':\n",
    "        lr_scheduler = lsf.OneCycle(\n",
    "            optimizer, total_steps, cfg.TRAIN.LR, list(cfg.TRAIN.MOMS), cfg.TRAIN.DIV_FACTOR, cfg.TRAIN.PCT_START\n",
    "        )\n",
    "    else:\n",
    "        lr_scheduler = lr_sched.LambdaLR(optimizer, lr_lbmd, last_epoch=last_epoch)\n",
    "\n",
    "    bnm_scheduler = train_utils.BNMomentumScheduler(model, bnm_lmbd, last_epoch=last_epoch)\n",
    "    return lr_scheduler, bnm_scheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## args input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "\n",
    "args = edict()\n",
    "\n",
    "args.cfg_file = 'cfgs/default.yaml'\n",
    "args.train_mode = 'rpn'\n",
    "args.batch_size = 4\n",
    "args.epochs = 200\n",
    "\n",
    "\n",
    "args.workers = 8\n",
    "args.ckpt_save_interval = 5\n",
    "args.output_dir = 'train_rcnn2'\n",
    "args.mgpus = False\n",
    "\n",
    "\n",
    "args.ckpt = None\n",
    "args.rpn_ckpt = None\n",
    "\n",
    "args.gt_database = 'gt_database/train_gt_database_3level_Car.pkl'\n",
    "args.rcnn_training_roi_dir = None\n",
    "args.rcnn_training_feature_dir = None\n",
    "\n",
    "\n",
    "args.train_with_eval = False\n",
    "args.rcnn_eval_roi_dir = None \n",
    "args.rcnn_eval_feature_dir = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.cfg_file= cfgs/default.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingling/Downloads/PointRCNN/tools/../lib/config.py:187: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "print(\"args.cfg_file= \" + args.cfg_file)\n",
    "if args.cfg_file is not None:\n",
    "    cfg_from_file(args.cfg_file)\n",
    "cfg.TAG = os.path.splitext(os.path.basename(args.cfg_file))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.train_mode = rpn\n"
     ]
    }
   ],
   "source": [
    "print(\"args.train_mode = \" + args.train_mode)\n",
    "if args.train_mode == 'rpn':\n",
    "    cfg.RPN.ENABLED = True\n",
    "    cfg.RCNN.ENABLED = False\n",
    "    root_result_dir = os.path.join('../', 'output', 'rpn', cfg.TAG)\n",
    "elif args.train_mode == 'rcnn':\n",
    "    cfg.RCNN.ENABLED = True\n",
    "    cfg.RPN.ENABLED = cfg.RPN.FIXED = True\n",
    "    root_result_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG)\n",
    "elif args.train_mode == 'rcnn_offline':\n",
    "    cfg.RCNN.ENABLED = True\n",
    "    cfg.RPN.ENABLED = False\n",
    "    root_result_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG)\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.output_dir = train_rcnn2\n"
     ]
    }
   ],
   "source": [
    "print(\"args.output_dir = \" + args.output_dir)\n",
    "if args.output_dir is not None:\n",
    "    root_result_dir = args.output_dir\n",
    "os.makedirs(root_result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-05 17:00:51,624   INFO  **********************Start logging**********************\n",
      "2019-11-05 17:00:51,624   INFO  CUDA_VISIBLE_DEVICES=ALL\n",
      "2019-11-05 17:00:51,624   INFO  cfg_file         cfgs/default.yaml\n",
      "2019-11-05 17:00:51,625   INFO  train_mode       rpn\n",
      "2019-11-05 17:00:51,625   INFO  batch_size       4\n",
      "2019-11-05 17:00:51,625   INFO  epochs           200\n",
      "2019-11-05 17:00:51,626   INFO  workers          8\n",
      "2019-11-05 17:00:51,626   INFO  ckpt_save_interval 5\n",
      "2019-11-05 17:00:51,626   INFO  output_dir       train_rcnn2\n",
      "2019-11-05 17:00:51,626   INFO  mgpus            False\n",
      "2019-11-05 17:00:51,627   INFO  ckpt             None\n",
      "2019-11-05 17:00:51,627   INFO  rpn_ckpt         None\n",
      "2019-11-05 17:00:51,627   INFO  gt_database      gt_database/train_gt_database_3level_Car.pkl\n",
      "2019-11-05 17:00:51,628   INFO  rcnn_training_roi_dir None\n",
      "2019-11-05 17:00:51,628   INFO  rcnn_training_feature_dir None\n",
      "2019-11-05 17:00:51,628   INFO  train_with_eval  False\n",
      "2019-11-05 17:00:51,628   INFO  rcnn_eval_roi_dir None\n",
      "2019-11-05 17:00:51,629   INFO  rcnn_eval_feature_dir None\n",
      "2019-11-05 17:00:51,629   INFO  cfg.TAG: default\n",
      "2019-11-05 17:00:51,630   INFO  cfg.CLASSES: Car\n",
      "2019-11-05 17:00:51,631   INFO  cfg.INCLUDE_SIMILAR_TYPE: True\n",
      "2019-11-05 17:00:51,631   INFO  cfg.AUG_DATA: True\n",
      "2019-11-05 17:00:51,631   INFO  cfg.AUG_METHOD_LIST: ['rotation', 'scaling', 'flip']\n",
      "2019-11-05 17:00:51,632   INFO  cfg.AUG_METHOD_PROB: [1.0, 1.0, 0.5]\n",
      "2019-11-05 17:00:51,632   INFO  cfg.AUG_ROT_RANGE: 18\n",
      "2019-11-05 17:00:51,632   INFO  cfg.GT_AUG_ENABLED: False\n",
      "2019-11-05 17:00:51,633   INFO  cfg.GT_EXTRA_NUM: 15\n",
      "2019-11-05 17:00:51,633   INFO  cfg.GT_AUG_RAND_NUM: True\n",
      "2019-11-05 17:00:51,633   INFO  cfg.GT_AUG_APPLY_PROB: 1.0\n",
      "2019-11-05 17:00:51,633   INFO  cfg.GT_AUG_HARD_RATIO: 0.6\n",
      "2019-11-05 17:00:51,634   INFO  cfg.PC_REDUCE_BY_RANGE: True\n",
      "2019-11-05 17:00:51,634   INFO  cfg.PC_AREA_SCOPE: [[-40.   40. ]\n",
      " [ -1.    3. ]\n",
      " [  0.   70.4]]\n",
      "2019-11-05 17:00:51,635   INFO  cfg.CLS_MEAN_SIZE: [[1.5256319 1.6285675 3.8831165]]\n",
      "2019-11-05 17:00:51,635   INFO  \n",
      "cfg.RPN = edict()\n",
      "2019-11-05 17:00:51,635   INFO  cfg.RPN.ENABLED: True\n",
      "2019-11-05 17:00:51,635   INFO  cfg.RPN.FIXED: False\n",
      "2019-11-05 17:00:51,636   INFO  cfg.RPN.USE_INTENSITY: False\n",
      "2019-11-05 17:00:51,636   INFO  cfg.RPN.LOC_XZ_FINE: True\n",
      "2019-11-05 17:00:51,636   INFO  cfg.RPN.LOC_SCOPE: 3.0\n",
      "2019-11-05 17:00:51,636   INFO  cfg.RPN.LOC_BIN_SIZE: 0.5\n",
      "2019-11-05 17:00:51,637   INFO  cfg.RPN.NUM_HEAD_BIN: 12\n",
      "2019-11-05 17:00:51,637   INFO  cfg.RPN.BACKBONE: pointnet2_msg\n",
      "2019-11-05 17:00:51,637   INFO  cfg.RPN.USE_BN: True\n",
      "2019-11-05 17:00:51,637   INFO  cfg.RPN.NUM_POINTS: 16384\n",
      "2019-11-05 17:00:51,638   INFO  \n",
      "cfg.RPN.SA_CONFIG = edict()\n",
      "2019-11-05 17:00:51,638   INFO  cfg.RPN.SA_CONFIG.NPOINTS: [4096, 1024, 256, 64]\n",
      "2019-11-05 17:00:51,638   INFO  cfg.RPN.SA_CONFIG.RADIUS: [[0.1, 0.5], [0.5, 1.0], [1.0, 2.0], [2.0, 4.0]]\n",
      "2019-11-05 17:00:51,638   INFO  cfg.RPN.SA_CONFIG.NSAMPLE: [[16, 32], [16, 32], [16, 32], [16, 32]]\n",
      "2019-11-05 17:00:51,639   INFO  cfg.RPN.SA_CONFIG.MLPS: [[[16, 16, 32], [32, 32, 64]], [[64, 64, 128], [64, 96, 128]], [[128, 196, 256], [128, 196, 256]], [[256, 256, 512], [256, 384, 512]]]\n",
      "2019-11-05 17:00:51,640   INFO  cfg.RPN.FP_MLPS: [[128, 128], [256, 256], [512, 512], [512, 512]]\n",
      "2019-11-05 17:00:51,640   INFO  cfg.RPN.CLS_FC: [128]\n",
      "2019-11-05 17:00:51,640   INFO  cfg.RPN.REG_FC: [128]\n",
      "2019-11-05 17:00:51,640   INFO  cfg.RPN.DP_RATIO: 0.5\n",
      "2019-11-05 17:00:51,641   INFO  cfg.RPN.LOSS_CLS: SigmoidFocalLoss\n",
      "2019-11-05 17:00:51,641   INFO  cfg.RPN.FG_WEIGHT: 15\n",
      "2019-11-05 17:00:51,641   INFO  cfg.RPN.FOCAL_ALPHA: [0.25, 0.75]\n",
      "2019-11-05 17:00:51,641   INFO  cfg.RPN.FOCAL_GAMMA: 2.0\n",
      "2019-11-05 17:00:51,642   INFO  cfg.RPN.REG_LOSS_WEIGHT: [1.0, 1.0, 1.0, 1.0]\n",
      "2019-11-05 17:00:51,642   INFO  cfg.RPN.LOSS_WEIGHT: [1.0, 1.0]\n",
      "2019-11-05 17:00:51,643   INFO  cfg.RPN.NMS_TYPE: normal\n",
      "2019-11-05 17:00:51,643   INFO  cfg.RPN.SCORE_THRESH: 0.3\n",
      "2019-11-05 17:00:51,643   INFO  \n",
      "cfg.RCNN = edict()\n",
      "2019-11-05 17:00:51,644   INFO  cfg.RCNN.ENABLED: False\n",
      "2019-11-05 17:00:51,644   INFO  cfg.RCNN.USE_RPN_FEATURES: True\n",
      "2019-11-05 17:00:51,644   INFO  cfg.RCNN.USE_MASK: True\n",
      "2019-11-05 17:00:51,644   INFO  cfg.RCNN.MASK_TYPE: seg\n",
      "2019-11-05 17:00:51,644   INFO  cfg.RCNN.USE_INTENSITY: False\n",
      "2019-11-05 17:00:51,645   INFO  cfg.RCNN.USE_DEPTH: True\n",
      "2019-11-05 17:00:51,645   INFO  cfg.RCNN.USE_SEG_SCORE: False\n",
      "2019-11-05 17:00:51,646   INFO  cfg.RCNN.ROI_SAMPLE_JIT: True\n",
      "2019-11-05 17:00:51,646   INFO  cfg.RCNN.ROI_FG_AUG_TIMES: 10\n",
      "2019-11-05 17:00:51,646   INFO  cfg.RCNN.REG_AUG_METHOD: multiple\n",
      "2019-11-05 17:00:51,646   INFO  cfg.RCNN.POOL_EXTRA_WIDTH: 1.0\n",
      "2019-11-05 17:00:51,647   INFO  cfg.RCNN.LOC_SCOPE: 1.5\n",
      "2019-11-05 17:00:51,647   INFO  cfg.RCNN.LOC_BIN_SIZE: 0.5\n",
      "2019-11-05 17:00:51,647   INFO  cfg.RCNN.NUM_HEAD_BIN: 9\n",
      "2019-11-05 17:00:51,648   INFO  cfg.RCNN.LOC_Y_BY_BIN: False\n",
      "2019-11-05 17:00:51,648   INFO  cfg.RCNN.LOC_Y_SCOPE: 0.5\n",
      "2019-11-05 17:00:51,648   INFO  cfg.RCNN.LOC_Y_BIN_SIZE: 0.25\n",
      "2019-11-05 17:00:51,649   INFO  cfg.RCNN.SIZE_RES_ON_ROI: False\n",
      "2019-11-05 17:00:51,649   INFO  cfg.RCNN.USE_BN: False\n",
      "2019-11-05 17:00:51,649   INFO  cfg.RCNN.DP_RATIO: 0.0\n",
      "2019-11-05 17:00:51,650   INFO  cfg.RCNN.BACKBONE: pointnet\n",
      "2019-11-05 17:00:51,650   INFO  cfg.RCNN.XYZ_UP_LAYER: [128, 128]\n",
      "2019-11-05 17:00:51,650   INFO  cfg.RCNN.NUM_POINTS: 512\n",
      "2019-11-05 17:00:51,650   INFO  \n",
      "cfg.RCNN.SA_CONFIG = edict()\n",
      "2019-11-05 17:00:51,651   INFO  cfg.RCNN.SA_CONFIG.NPOINTS: [128, 32, -1]\n",
      "2019-11-05 17:00:51,651   INFO  cfg.RCNN.SA_CONFIG.RADIUS: [0.2, 0.4, 100]\n",
      "2019-11-05 17:00:51,651   INFO  cfg.RCNN.SA_CONFIG.NSAMPLE: [64, 64, 64]\n",
      "2019-11-05 17:00:51,651   INFO  cfg.RCNN.SA_CONFIG.MLPS: [[128, 128, 128], [128, 128, 256], [256, 256, 512]]\n",
      "2019-11-05 17:00:51,652   INFO  cfg.RCNN.CLS_FC: [256, 256]\n",
      "2019-11-05 17:00:51,652   INFO  cfg.RCNN.REG_FC: [256, 256]\n",
      "2019-11-05 17:00:51,653   INFO  cfg.RCNN.LOSS_CLS: BinaryCrossEntropy\n",
      "2019-11-05 17:00:51,653   INFO  cfg.RCNN.FOCAL_ALPHA: [0.25, 0.75]\n",
      "2019-11-05 17:00:51,653   INFO  cfg.RCNN.FOCAL_GAMMA: 2.0\n",
      "2019-11-05 17:00:51,654   INFO  cfg.RCNN.CLS_WEIGHT: [1. 1. 1.]\n",
      "2019-11-05 17:00:51,654   INFO  cfg.RCNN.CLS_FG_THRESH: 0.6\n",
      "2019-11-05 17:00:51,654   INFO  cfg.RCNN.CLS_BG_THRESH: 0.45\n",
      "2019-11-05 17:00:51,655   INFO  cfg.RCNN.CLS_BG_THRESH_LO: 0.05\n",
      "2019-11-05 17:00:51,655   INFO  cfg.RCNN.REG_FG_THRESH: 0.55\n",
      "2019-11-05 17:00:51,655   INFO  cfg.RCNN.FG_RATIO: 0.5\n",
      "2019-11-05 17:00:51,655   INFO  cfg.RCNN.ROI_PER_IMAGE: 64\n",
      "2019-11-05 17:00:51,656   INFO  cfg.RCNN.HARD_BG_RATIO: 0.8\n",
      "2019-11-05 17:00:51,656   INFO  cfg.RCNN.SCORE_THRESH: 0.3\n",
      "2019-11-05 17:00:51,656   INFO  cfg.RCNN.NMS_THRESH: 0.1\n",
      "2019-11-05 17:00:51,657   INFO  \n",
      "cfg.TRAIN = edict()\n",
      "2019-11-05 17:00:51,658   INFO  cfg.TRAIN.SPLIT: train\n",
      "2019-11-05 17:00:51,658   INFO  cfg.TRAIN.VAL_SPLIT: smallval\n",
      "2019-11-05 17:00:51,658   INFO  cfg.TRAIN.LR: 0.002\n",
      "2019-11-05 17:00:51,658   INFO  cfg.TRAIN.LR_CLIP: 1e-05\n",
      "2019-11-05 17:00:51,659   INFO  cfg.TRAIN.LR_DECAY: 0.5\n",
      "2019-11-05 17:00:51,659   INFO  cfg.TRAIN.DECAY_STEP_LIST: [100, 150, 180, 200]\n",
      "2019-11-05 17:00:51,659   INFO  cfg.TRAIN.LR_WARMUP: True\n",
      "2019-11-05 17:00:51,660   INFO  cfg.TRAIN.WARMUP_MIN: 0.0002\n",
      "2019-11-05 17:00:51,660   INFO  cfg.TRAIN.WARMUP_EPOCH: 1\n",
      "2019-11-05 17:00:51,660   INFO  cfg.TRAIN.BN_MOMENTUM: 0.1\n",
      "2019-11-05 17:00:51,660   INFO  cfg.TRAIN.BN_DECAY: 0.5\n",
      "2019-11-05 17:00:51,661   INFO  cfg.TRAIN.BNM_CLIP: 0.01\n",
      "2019-11-05 17:00:51,661   INFO  cfg.TRAIN.BN_DECAY_STEP_LIST: [1000]\n",
      "2019-11-05 17:00:51,662   INFO  cfg.TRAIN.OPTIMIZER: adam_onecycle\n",
      "2019-11-05 17:00:51,662   INFO  cfg.TRAIN.WEIGHT_DECAY: 0.001\n",
      "2019-11-05 17:00:51,662   INFO  cfg.TRAIN.MOMENTUM: 0.9\n",
      "2019-11-05 17:00:51,662   INFO  cfg.TRAIN.MOMS: [0.95, 0.85]\n",
      "2019-11-05 17:00:51,663   INFO  cfg.TRAIN.DIV_FACTOR: 10.0\n",
      "2019-11-05 17:00:51,663   INFO  cfg.TRAIN.PCT_START: 0.4\n",
      "2019-11-05 17:00:51,663   INFO  cfg.TRAIN.GRAD_NORM_CLIP: 1.0\n",
      "2019-11-05 17:00:51,664   INFO  cfg.TRAIN.RPN_PRE_NMS_TOP_N: 9000\n",
      "2019-11-05 17:00:51,664   INFO  cfg.TRAIN.RPN_POST_NMS_TOP_N: 512\n",
      "2019-11-05 17:00:51,664   INFO  cfg.TRAIN.RPN_NMS_THRESH: 0.85\n",
      "2019-11-05 17:00:51,664   INFO  cfg.TRAIN.RPN_DISTANCE_BASED_PROPOSE: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-05 17:00:51,664   INFO  \n",
      "cfg.TEST = edict()\n",
      "2019-11-05 17:00:51,665   INFO  cfg.TEST.SPLIT: val\n",
      "2019-11-05 17:00:51,665   INFO  cfg.TEST.RPN_PRE_NMS_TOP_N: 9000\n",
      "2019-11-05 17:00:51,665   INFO  cfg.TEST.RPN_POST_NMS_TOP_N: 100\n",
      "2019-11-05 17:00:51,665   INFO  cfg.TEST.RPN_NMS_THRESH: 0.8\n",
      "2019-11-05 17:00:51,666   INFO  cfg.TEST.RPN_DISTANCE_BASED_PROPOSE: True\n"
     ]
    }
   ],
   "source": [
    "log_file = os.path.join(root_result_dir, 'log_train.txt')\n",
    "logger = create_logger(log_file)\n",
    "logger.info('**********************Start logging**********************')\n",
    "\n",
    "# log to file\n",
    "gpu_list = os.environ['CUDA_VISIBLE_DEVICES'] if 'CUDA_VISIBLE_DEVICES' in os.environ.keys() else 'ALL'\n",
    "logger.info('CUDA_VISIBLE_DEVICES=%s' % gpu_list)\n",
    "\n",
    "for key, val in vars(args).items():\n",
    "    logger.info(\"{:16} {}\".format(key, val))\n",
    "    \n",
    "save_config_to_file(cfg, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard log\n",
    "tb_log = SummaryWriter(log_dir=os.path.join(root_result_dir, 'tensorboard'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-05 17:00:51,864   INFO  Loading gt_database(easy(pt_num>100): 5651, hard(pt_num<=100): 5366) from gt_database/train_gt_database_3level_Car.pkl\n",
      "2019-11-05 17:00:51,865   INFO  Loading TRAIN samples from ../data/KITTI/object/training/label_2 ...\n",
      "2019-11-05 17:00:52,447   INFO  Done: filter TRAIN results: 3265 / 3712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataloader & network & optimizer\n",
    "train_loader, test_loader = create_dataloader(logger)\n",
    "model = PointRCNN(num_classes=train_loader.dataset.num_class, use_xyz=True, mode='TRAIN')\n",
    "optimizer = create_optimizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.mgpus = False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PointRCNN(\n",
       "  (rpn): RPN(\n",
       "    (backbone_net): Pointnet2MSG(\n",
       "      (SA_modules): ModuleList(\n",
       "        (0): PointnetSAModuleMSG(\n",
       "          (groupers): ModuleList(\n",
       "            (0): QueryAndGroup()\n",
       "            (1): QueryAndGroup()\n",
       "          )\n",
       "          (mlps): ModuleList(\n",
       "            (0): SharedMLP(\n",
       "              (layer0): Conv2d(\n",
       "                (conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer1): Conv2d(\n",
       "                (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer2): Conv2d(\n",
       "                (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): SharedMLP(\n",
       "              (layer0): Conv2d(\n",
       "                (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer1): Conv2d(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer2): Conv2d(\n",
       "                (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PointnetSAModuleMSG(\n",
       "          (groupers): ModuleList(\n",
       "            (0): QueryAndGroup()\n",
       "            (1): QueryAndGroup()\n",
       "          )\n",
       "          (mlps): ModuleList(\n",
       "            (0): SharedMLP(\n",
       "              (layer0): Conv2d(\n",
       "                (conv): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer1): Conv2d(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer2): Conv2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): SharedMLP(\n",
       "              (layer0): Conv2d(\n",
       "                (conv): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer1): Conv2d(\n",
       "                (conv): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer2): Conv2d(\n",
       "                (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PointnetSAModuleMSG(\n",
       "          (groupers): ModuleList(\n",
       "            (0): QueryAndGroup()\n",
       "            (1): QueryAndGroup()\n",
       "          )\n",
       "          (mlps): ModuleList(\n",
       "            (0): SharedMLP(\n",
       "              (layer0): Conv2d(\n",
       "                (conv): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer1): Conv2d(\n",
       "                (conv): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer2): Conv2d(\n",
       "                (conv): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): SharedMLP(\n",
       "              (layer0): Conv2d(\n",
       "                (conv): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer1): Conv2d(\n",
       "                (conv): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer2): Conv2d(\n",
       "                (conv): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PointnetSAModuleMSG(\n",
       "          (groupers): ModuleList(\n",
       "            (0): QueryAndGroup()\n",
       "            (1): QueryAndGroup()\n",
       "          )\n",
       "          (mlps): ModuleList(\n",
       "            (0): SharedMLP(\n",
       "              (layer0): Conv2d(\n",
       "                (conv): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer1): Conv2d(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer2): Conv2d(\n",
       "                (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): SharedMLP(\n",
       "              (layer0): Conv2d(\n",
       "                (conv): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer1): Conv2d(\n",
       "                (conv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "              (layer2): Conv2d(\n",
       "                (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(\n",
       "                  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (activation): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (FP_modules): ModuleList(\n",
       "        (0): PointnetFPModule(\n",
       "          (mlp): SharedMLP(\n",
       "            (layer0): Conv2d(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(\n",
       "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "            (layer1): Conv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(\n",
       "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PointnetFPModule(\n",
       "          (mlp): SharedMLP(\n",
       "            (layer0): Conv2d(\n",
       "              (conv): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(\n",
       "                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "            (layer1): Conv2d(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(\n",
       "                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PointnetFPModule(\n",
       "          (mlp): SharedMLP(\n",
       "            (layer0): Conv2d(\n",
       "              (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(\n",
       "                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "            (layer1): Conv2d(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(\n",
       "                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PointnetFPModule(\n",
       "          (mlp): SharedMLP(\n",
       "            (layer0): Conv2d(\n",
       "              (conv): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(\n",
       "                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "            (layer1): Conv2d(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(\n",
       "                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rpn_cls_layer): Sequential(\n",
       "      (0): Conv1d(\n",
       "        (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(\n",
       "          (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Conv1d(\n",
       "        (conv): Conv1d(128, 1, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (rpn_reg_layer): Sequential(\n",
       "      (0): Conv1d(\n",
       "        (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(\n",
       "          (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Conv1d(\n",
       "        (conv): Conv1d(128, 76, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (rpn_cls_loss_func): SigmoidFocalClassificationLoss()\n",
       "    (proposal_layer): ProposalLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"args.mgpus = \"+ str(args.mgpus))\n",
    "if args.mgpus:\n",
    "    model = nn.DataParallel(model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.ckpt = None\n"
     ]
    }
   ],
   "source": [
    "# load checkpoint if it is possible\n",
    "start_epoch = it = 0\n",
    "last_epoch = -1\n",
    "if args.ckpt is not None:\n",
    "    pure_model = model.module if isinstance(model, torch.nn.DataParallel) else model\n",
    "    it, start_epoch = train_utils.load_checkpoint(pure_model, optimizer, filename=args.ckpt, logger=logger)\n",
    "    last_epoch = start_epoch + 1\n",
    "    \n",
    "print(\"args.ckpt = \"+ str(args.ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler, bnm_scheduler = create_scheduler(optimizer, total_steps=len(train_loader) * args.epochs,\n",
    "                                               last_epoch=last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.rpn_ckpt =  None\n"
     ]
    }
   ],
   "source": [
    "if args.rpn_ckpt is not None:\n",
    "    pure_model = model.module if isinstance(model, torch.nn.DataParallel) else model\n",
    "    total_keys = pure_model.state_dict().keys().__len__()\n",
    "    train_utils.load_part_ckpt(pure_model, filename=args.rpn_ckpt, logger=logger, total_keys=total_keys)\n",
    "    \n",
    "    \n",
    "print(\"args.rpn_ckpt =  \" + str(args.rpn_ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if = False\n"
     ]
    }
   ],
   "source": [
    "if cfg.TRAIN.LR_WARMUP and cfg.TRAIN.OPTIMIZER != 'adam_onecycle':\n",
    "    lr_warmup_scheduler = train_utils.CosineWarmupLR(optimizer, T_max=cfg.TRAIN.WARMUP_EPOCH * len(train_loader),\n",
    "                                                  eta_min=cfg.TRAIN.WARMUP_MIN)\n",
    "else:\n",
    "    lr_warmup_scheduler = None\n",
    "    \n",
    "print(\"if = \" + str(cfg.TRAIN.LR_WARMUP and cfg.TRAIN.OPTIMIZER != 'adam_onecycle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-05 17:01:20,593   INFO  **********************Start training**********************\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "logger.info('**********************Start training**********************')\n",
    "ckpt_dir = os.path.join(root_result_dir, 'ckpt')\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "trainer = train_utils.Trainer(\n",
    "    model,\n",
    "    train_functions.model_joint_fn_decorator(),\n",
    "    optimizer,\n",
    "    ckpt_dir=ckpt_dir,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    bnm_scheduler=bnm_scheduler,\n",
    "    model_fn_eval=train_functions.model_joint_fn_decorator(),\n",
    "    tb_log=tb_log,\n",
    "    eval_frequency=1,\n",
    "    lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "    warmup_epoch=cfg.TRAIN.WARMUP_EPOCH,\n",
    "    grad_norm_clip=cfg.TRAIN.GRAD_NORM_CLIP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(\n",
    "    it,\n",
    "    start_epoch,\n",
    "    args.epochs,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    ckpt_save_interval=args.ckpt_save_interval,\n",
    "    lr_scheduler_each_iter=(cfg.TRAIN.OPTIMIZER == 'adam_onecycle')\n",
    ")\n",
    "\n",
    "logger.info('**********************End training**********************')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "211px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
