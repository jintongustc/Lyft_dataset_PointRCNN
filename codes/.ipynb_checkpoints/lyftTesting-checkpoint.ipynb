{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../lib/')\n",
    "sys.path.append('../lib/net/')\n",
    "sys.path.append('../lib/rpn/')\n",
    "sys.path.append('../lib/utils/iou3d/')\n",
    "sys.path.append('../lib/utils/roipool3d/')\n",
    "sys.path.append('../lib/utils/roipool3d/build/')\n",
    "sys.path.append('../pointnet2_lib/')\n",
    "sys.path.append('../pointnet2_lib/')\n",
    "sys.path.append('../pointnet2_lib/pointnet2/')\n",
    "sys.path.append('../pointnet2_lib/tools/')\n",
    "sys.path.append('./train_utils/')\n",
    "sys.path.append('./kitti_object_eval_python/')\n",
    "sys.path.append('./cfgs/')\n",
    "\n",
    "import _init_path\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from lib.net.point_rcnn import PointRCNN\n",
    "from lib.datasets.kitti_rcnn_dataset import KittiRCNNDataset\n",
    "import tools.train_utils.train_utils as train_utils\n",
    "from lib.utils.bbox_transform import decode_bbox_target\n",
    "from tools.kitti_object_eval_python.evaluate import evaluate as kitti_evaluate\n",
    "\n",
    "from lib.config import cfg, cfg_from_file, save_config_to_file, cfg_from_list\n",
    "import argparse\n",
    "import lib.utils.kitti_utils as kitti_utils\n",
    "import lib.utils.iou3d.iou3d_utils as iou3d_utils\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "import json\n",
    "import math \n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import Tuple,List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import sklearn.metrics\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib import animation, rc\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as ts\n",
    "from plotly.offline import plot, init_notebook_mode\n",
    "import plotly.figure_factory as ft\n",
    "init_notebook_mode(connected=True)\n",
    "from pyquaternion import Quaternion\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from lyft_dataset_sdk.utils.map_mask import MapMask\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, box_in_image, BoxVisibility\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix\n",
    "from pathlib import Path\n",
    "\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset,LyftDatasetExplorer\n",
    "from lyft_dataset_sdk.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix\n",
    "import time\n",
    "from lyft_dataset_sdk.utils.map_mask import MapMask\n",
    "\n",
    "import struct\n",
    "from abc import ABC, abstractmethod\n",
    "from functools import reduce\n",
    "from typing import Tuple, List, Dict\n",
    "import copy\n",
    "from shutil import copyfile\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## args input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1024)  # set the same seed\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "args = edict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_class = 'car'\n",
    "args.ckpt = '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
    "args.output_dir = '../predicted/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.cfg_file = 'cfgs/' + saved_class + '.yaml'\n",
    "args.eval_mode = 'rcnn'\n",
    "\n",
    "\n",
    "args.eval_all = False\n",
    "args.test = True \n",
    "args.rpn_ckpt = None\n",
    "args.rcnn_ckpt = None\n",
    "\n",
    "\n",
    "args.batch_size = 3\n",
    "args.workers = 4\n",
    "args.extra_tag = 'default'\n",
    "args.ckpt_dir = None\n",
    "\n",
    "\n",
    "args.save_result = False\n",
    "args.save_rpn_feature = False\n",
    "\n",
    "\n",
    "args.random_select = True\n",
    "args.start_epoch = 0\n",
    "args.rcnn_eval_roi_dir = None\n",
    "args.rcnn_eval_feature_dir = None\n",
    "args.set_cfgs = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ling's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logger(log_file):\n",
    "    log_format = '%(asctime)s  %(levelname)5s  %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_format, filename=log_file)\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    console.setFormatter(logging.Formatter(log_format))\n",
    "    logging.getLogger(__name__).addHandler(console)\n",
    "    return logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(logger):\n",
    "    mode = 'TEST' \n",
    "    DATA_PATH = os.path.join('..', 'data')\n",
    "\n",
    "    # create dataloader\n",
    "    test_set = KittiRCNNDataset(root_dir=DATA_PATH, npoints=cfg.RPN.NUM_POINTS, split='test', mode=mode,\n",
    "                                random_select=args.random_select,\n",
    "                                rcnn_eval_roi_dir=args.rcnn_eval_roi_dir,\n",
    "                                rcnn_eval_feature_dir=args.rcnn_eval_feature_dir,\n",
    "                                classes=cfg.CLASSES,\n",
    "                                logger=logger)\n",
    "\n",
    "    test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, pin_memory=True,\n",
    "                             num_workers=args.workers, collate_fn=test_set.collate_batch)\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save_predicted_boxes3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predicted_boxes3d(pred_boxes3d, scores_pred, savefile):\n",
    "    \"\"\"\n",
    "        args:\n",
    "            pred_boxes3d: numpy.ndarray (ncars * 7[x, y, z, height, width, length, yaw])\n",
    "            \n",
    "            scores_pred: numpy.ndarray (ncars * 1)\n",
    "            \n",
    "            savefile: savefile name, save format: [confidence, x, y, z, width, length, height, yaw, classname]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    with open(savefile, 'w') as f:\n",
    "        for k in range(pred_boxes3d.shape[0]):\n",
    "            print('%.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %s' %\n",
    "                  (scores_pred[k], pred_boxes3d[k, 0], pred_boxes3d[k, 1], pred_boxes3d[k, 2], \n",
    "                   pred_boxes3d[k, 4], pred_boxes3d[k, 5], pred_boxes3d[k, 3],pred_boxes3d[k, 6],\n",
    "                  saved_class), file=f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load_ckpt_based_on_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckpt_based_on_args(model, logger):\n",
    "    if args.ckpt is not None:\n",
    "        train_utils.load_checkpoint(model, filename=args.ckpt, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### detect_one_epoch_join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_one_epoch_joint(model, dataloader, epoch_id, result_dir, logger, sample_token):\n",
    "    '''\n",
    "    use joint (rpn + rcnn) model to detect object\n",
    "    \n",
    "    output:\n",
    "        predicted 3dboxes stored in result_dir\n",
    "    \n",
    "    '''\n",
    "    np.random.seed(666)\n",
    "    MEAN_SIZE = torch.from_numpy(cfg.CLS_MEAN_SIZE[0]).cuda()\n",
    "\n",
    "    predicted_boxes3d_dir = os.path.join(result_dir, 'pred_boxes3d', cfg.CLASSES)\n",
    "    os.makedirs(predicted_boxes3d_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    logger.info('---- EPOCH %s JOINT PREDICTION ----' % epoch_id)\n",
    "    logger.info('==> Output file: %s' % predicted_boxes3d_dir)\n",
    "    model.eval()\n",
    "\n",
    "    thresh_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    total_recalled_bbox_list, total_gt_bbox = [0] * 5, 0\n",
    "    total_roi_recalled_bbox_list = [0] * 5\n",
    "    dataset = dataloader.dataset\n",
    "    cnt = final_total = total_cls_acc = total_cls_acc_refined = total_rpn_iou = 0\n",
    "\n",
    "    progress_bar = tqdm.tqdm(total=len(dataloader), leave=True, desc='eval')\n",
    "    for data in dataloader:\n",
    "        cnt += 1\n",
    "        sample_id, pts_rect, pts_features, pts_input = \\\n",
    "            data['sample_id'], data['pts_rect'], data['pts_features'], data['pts_input']\n",
    "        batch_size = len(sample_id)\n",
    "        inputs = torch.from_numpy(pts_input).cuda(non_blocking=True).float()\n",
    "        input_data = {'pts_input': inputs}\n",
    "\n",
    "        # model inference\n",
    "        ret_dict = model(input_data)\n",
    "\n",
    "        roi_scores_raw = ret_dict['roi_scores_raw']  # (B, M)\n",
    "        roi_boxes3d = ret_dict['rois']  # (B, M, 7)\n",
    "        seg_result = ret_dict['seg_result'].long()  # (B, N)\n",
    "\n",
    "        rcnn_cls = ret_dict['rcnn_cls'].view(batch_size, -1, ret_dict['rcnn_cls'].shape[1])\n",
    "        rcnn_reg = ret_dict['rcnn_reg'].view(batch_size, -1, ret_dict['rcnn_reg'].shape[1])  # (B, M, C)\n",
    "\n",
    "\n",
    "        # bounding box regression\n",
    "        anchor_size = MEAN_SIZE\n",
    "        if cfg.RCNN.SIZE_RES_ON_ROI:\n",
    "            assert False\n",
    "\n",
    "        pred_boxes3d = decode_bbox_target(roi_boxes3d.view(-1, 7), rcnn_reg.view(-1, rcnn_reg.shape[-1]),\n",
    "                                          anchor_size=anchor_size,\n",
    "                                          loc_scope=cfg.RCNN.LOC_SCOPE,\n",
    "                                          loc_bin_size=cfg.RCNN.LOC_BIN_SIZE,\n",
    "                                          num_head_bin=cfg.RCNN.NUM_HEAD_BIN,\n",
    "                                          get_xz_fine=True, get_y_by_bin=cfg.RCNN.LOC_Y_BY_BIN,\n",
    "                                          loc_y_scope=cfg.RCNN.LOC_Y_SCOPE, loc_y_bin_size=cfg.RCNN.LOC_Y_BIN_SIZE,\n",
    "                                          get_ry_fine=True).view(batch_size, -1, 7)\n",
    "\n",
    "        # scoring\n",
    "        if rcnn_cls.shape[2] == 1:\n",
    "            raw_scores = rcnn_cls  # (B, M, 1)\n",
    "\n",
    "            norm_scores = torch.sigmoid(raw_scores)\n",
    "            pred_classes = (norm_scores > cfg.RCNN.SCORE_THRESH).long()\n",
    "        else:\n",
    "            pred_classes = torch.argmax(rcnn_cls, dim=1).view(-1)\n",
    "            cls_norm_scores = F.softmax(rcnn_cls, dim=1)\n",
    "            raw_scores = rcnn_cls[:, pred_classes]\n",
    "            norm_scores = cls_norm_scores[:, pred_classes]\n",
    "            \n",
    "        \n",
    "        disp_dict = {'mode': 'Predicting'}\n",
    "        progress_bar.set_postfix(disp_dict)\n",
    "        progress_bar.update()\n",
    "\n",
    "        # scores thresh\n",
    "        inds = norm_scores > cfg.RCNN.SCORE_THRESH\n",
    "\n",
    "        for k in range(batch_size):\n",
    "            cur_inds = inds[k].view(-1)\n",
    "            if cur_inds.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            pred_boxes3d_selected = pred_boxes3d[k, cur_inds]\n",
    "            raw_scores_selected = raw_scores[k, cur_inds]\n",
    "            norm_scores_selected = norm_scores[k, cur_inds]\n",
    "            \n",
    "\n",
    "            # NMS thresh\n",
    "            # rotated nms\n",
    "            boxes_bev_selected = kitti_utils.boxes3d_to_bev_torch(pred_boxes3d_selected)\n",
    "            keep_idx = iou3d_utils.nms_gpu(boxes_bev_selected, raw_scores_selected, cfg.RCNN.NMS_THRESH).view(-1)\n",
    "            pred_boxes3d_selected = pred_boxes3d_selected[keep_idx]\n",
    "            scores_selected = raw_scores_selected[keep_idx]\n",
    "            pred_boxes3d_selected, scores_selected = pred_boxes3d_selected.cpu().numpy(), scores_selected.cpu().numpy()\n",
    "\n",
    "            cur_sample_id = sample_id[k]\n",
    "            savefile = os.path.join(predicted_boxes3d_dir, '%06d.txt' % cur_sample_id)\n",
    "            \n",
    "            save_predicted_boxes3d(pred_boxes3d_selected, norm_scores_selected, savefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tong's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### link folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s ../../3d-object-detection-for-autonomous-vehicles/test_images images\n",
    "!ln -s ../../3d-object-detection-for-autonomous-vehicles/test_maps maps\n",
    "!ln -s ../../3d-object-detection-for-autonomous-vehicles/test_lidar lidar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LyftDataset(data_path='.', json_path='../../3d-object-detection-for-autonomous-vehicles/test_data', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output transformation: global_from_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_global_from_rect(sample_ID,args):\n",
    "    #args = [x,y,z,width,length,height,yaw]\n",
    "    # get the label from the sample_ID\n",
    "    import math\n",
    "    sample_token=sample_ID \n",
    "    sample = test_dataset.get(\"sample\", sample_token)\n",
    "\n",
    "    sample_lidar_token = sample[\"data\"][\"LIDAR_TOP\"]\n",
    "    lidar_data = test_dataset.get(\"sample_data\", sample_lidar_token)\n",
    "\n",
    "    # get lidar calibration info\n",
    "    ego_pose = test_dataset.get(\"ego_pose\", lidar_data[\"ego_pose_token\"])\n",
    "    calibrated_sensor = test_dataset.get(\"calibrated_sensor\", lidar_data[\"calibrated_sensor_token\"])\n",
    "\n",
    "    # get the transformation matrix from calibration info\n",
    "    Tr_rect_sensor = np.array([[-1,0,0,0],[0,0,1,0],[0,-1,0,0],[0,0,0,1]])\n",
    "\n",
    "    global_from_car = transform_matrix(ego_pose['translation'],\n",
    "                                       Quaternion(ego_pose['rotation']), inverse=False)\n",
    "    car_from_sensor = transform_matrix(calibrated_sensor['translation'], Quaternion(calibrated_sensor['rotation']),\n",
    "                                        inverse=False)\n",
    "    global_from_sensor = np.dot(global_from_car,car_from_sensor)\n",
    "    \n",
    "    global_from_rect = np.dot(global_from_sensor,Tr_rect_sensor)\n",
    "    \n",
    "    center_x = args[0]\n",
    "    center_y = args[1]\n",
    "    center_z = args[2]\n",
    "    width = args[3]\n",
    "    length = args[4]\n",
    "    height = args[5]\n",
    "    yaw = args[6]\n",
    "        \n",
    "        \n",
    "        \n",
    "    # transfrom the center point from global to sensor (center_x,center_y,center_z)->(x,y,z)\n",
    "    tmp = np.array([[center_x],[center_y],[center_z],[1.0]])\n",
    "    coor = np.dot(global_from_rect,tmp)\n",
    "    x = coor[0][0]\n",
    "    y = coor[1][0]\n",
    "    z = coor[2][0]\n",
    "\n",
    "    # transform the yaw from sensor to global yaw->yaw_sensor\n",
    "    # yaw vector += center vector\n",
    "    x_yaw = center_x - np.sin(yaw)\n",
    "    z_yaw = center_z + np.cos(yaw)\n",
    "    y_yaw = center_y\n",
    "    # transfer yaw vector to sensor\n",
    "    coor_yaw = np.dot(global_from_rect,np.array([[x_yaw],[y_yaw],[z_yaw],[1.0]]))\n",
    "    x_yaw_global = coor_yaw[0][0]\n",
    "    y_yaw_global = coor_yaw[1][0]\n",
    "    z_yaw_global = coor_yaw[2][0]\n",
    "    # the angle between yaw_sensor and the y axis\n",
    "    #yaw_new = np.arccos(np.clip(np.dot((1,0),(y_yaw_global - y,x_yaw_global - x)), -1.0, 1.0))\n",
    "    yaw_new = math.atan2(-(x_yaw_global - x),y_yaw_global - y)\n",
    "    \n",
    "        \n",
    "    return [x,y,z,width,length,height,yaw_new]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lidar_filepath_from_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lidar_filepath_from_id(sample_token):\n",
    "    sample = test_dataset.get(\"sample\", sample_token)\n",
    "\n",
    "    sample_lidar_token = sample[\"data\"][\"LIDAR_TOP\"]\n",
    "    \n",
    "    lidar_path = test_dataset.get_sample_data_path(sample_lidar_token)\n",
    "    return lidar_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write_image_from_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image_from_id(image_folder,kitti_id,sample_token):\n",
    "    \n",
    "\n",
    "    sample = test_dataset.get(\"sample\", sample_token)\n",
    "\n",
    "    sample_cam_token = sample[\"data\"][\"CAM_FRONT_LEFT\"]\n",
    "    cam_data = test_dataset.get(\"sample_data\", sample_cam_token)\n",
    "    cam_filepath = test_dataset.get_sample_data_path(sample_cam_token)\n",
    "    \n",
    "    im = Image.open(cam_filepath)\n",
    "    im.save(os.path.join(image_folder,\"{:06n}\".format(kitti_id)+\".png\"), \"PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calib file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_calib(calib_folder,idx):\n",
    "    \n",
    "    label_save_fn = os.path.join(calib_folder,\"{:06n}\".format(idx)+'.txt')\n",
    "    Tr_lyft_rect = np.array([-1,  0,  0,  0, 0,  0, -1,  0, 0,  1,  0,  0])\n",
    "    R0_rect = np.array([1,0,0,0,1,0,0,0,1])\n",
    "    with open(label_save_fn, 'w') as f:\n",
    "\n",
    "        print('P0: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f'  %\n",
    "                          (1,0,0,0,0,1,0,0,0,0,1,0),file=f)\n",
    "        print('P1: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f'  %\n",
    "                          (1,0,0,0,0,1,0,0,0,0,1,0),file=f)\n",
    "        print('P2: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f'  %\n",
    "                          (1,0,0,0,0,1,0,0,0,0,1,0),file=f)\n",
    "        print('P3: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f'  %\n",
    "                          (1,0,0,0,0,1,0,0,0,0,1,0),file=f)\n",
    "\n",
    "        print('R0_rect: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f' %\n",
    "                          (R0_rect[0], R0_rect[1],R0_rect[2], R0_rect[3], R0_rect[4],\n",
    "                           R0_rect[5], R0_rect[6], R0_rect[7], R0_rect[8]),file=f)\n",
    "\n",
    "        print('Tr_velo_to_cam: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f' %\n",
    "                          (-1,0,0,0,0,0,-1,0,0,1,0,0),file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge config and log to file\n",
    "if args.cfg_file is not None:\n",
    "    cfg_from_file(args.cfg_file)\n",
    "       \n",
    "cfg.TAG = os.path.splitext(os.path.basename(args.cfg_file))[0]\n",
    "\n",
    "\n",
    "# args.eval_mode == 'rcnn':\n",
    "cfg.RCNN.ENABLED = True\n",
    "cfg.RPN.ENABLED = cfg.RPN.FIXED = True\n",
    "root_result_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG)\n",
    "ckpt_dir = args.ckpt_dir\n",
    "\n",
    "if args.output_dir is not None:\n",
    "    root_result_dir = args.output_dir\n",
    "    \n",
    " # set epoch_id and output dir\n",
    "num_list = re.findall(r'\\d+', args.ckpt) if args.ckpt is not None else []\n",
    "epoch_id = num_list[-1] if num_list.__len__() > 0 else 'no_number'\n",
    "root_result_dir = os.path.join(root_result_dir, 'epoch_%s' % epoch_id)\n",
    "\n",
    "os.makedirs(root_result_dir, exist_ok=True)\n",
    "\n",
    "log_file = os.path.join(root_result_dir, 'log_eval_one.txt')\n",
    "logger = create_logger(log_file)\n",
    "logger.info('**********************Start logging**********************')\n",
    "for key, val in vars(args).items():\n",
    "    logger.info(\"{:16} {}\".format(key, val))\n",
    "save_config_to_file(cfg, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_folder = \"/home/lingling/Downloads/Lyft_PointRCNN/data/KITTI/object/testing/calib/\"\n",
    "lidar_folder = '/home/lingling/Downloads/Lyft_PointRCNN/data/KITTI/object/testing/velodyne'\n",
    "image_folder = '/home/lingling/Downloads/Lyft_PointRCNN/data/KITTI/object/testing/image_2'\n",
    "testtxtfile = '/home/lingling/Downloads/Lyft_PointRCNN/data/KITTI/ImageSets/test.txt'\n",
    "\n",
    "os.makedirs(calib_folder, exist_ok=True)\n",
    "os.makedirs(lidar_folder, exist_ok=True)\n",
    "os.makedirs(image_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "#os.makedirs(lidar_folder)\n",
    "\n",
    "df = pd.read_csv('sample_submission.csv')\n",
    "lyfttest_Id = df['Id']\n",
    "\n",
    "\n",
    "kitti_id = 20548\n",
    "while(kitti_id < len(lyfttest_Id)):\n",
    "    \n",
    "    sample_token = lyfttest_Id[kitti_id]\n",
    "    \"\"\"\n",
    "        prepare test.txt, calibration file and the lidar files\n",
    "    \"\"\"\n",
    "    # write test.txt\n",
    "    if kitti_id % 10 == 0:\n",
    "        with open(testtxtfile, 'w') as f:\n",
    "            print(\"{:06n}\".format(kitti_id),file=f)\n",
    "    else:\n",
    "        with open(testtxtfile, 'a') as f:\n",
    "            print(\"{:06n}\".format(kitti_id),file=f)\n",
    "    \n",
    "    # write calibration file\n",
    "    write_calib(calib_folder,kitti_id)\n",
    "    \n",
    "    # extract lidar file path\n",
    "    lidar_filepath = lidar_filepath_from_id(sample_token)\n",
    "    # move lidar to path\n",
    "    lidar_savefilename = \"{:06n}\".format(kitti_id)+'.bin'\n",
    "    copyfile(lidar_filepath,os.path.join(lidar_folder, lidar_savefilename)) \n",
    "    # write image\n",
    "    write_image_from_id(image_folder,kitti_id,sample_token)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "        prediction part\n",
    "    \"\"\"\n",
    "    # predict every 10 files or at the last file\n",
    "    if kitti_id %10 == 9 or kitti_id ==  len(lyfttest_Id) -1:\n",
    "        # predition - arges\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # create dataloader & network\n",
    "            test_loader = create_dataloader(logger)\n",
    "            model = PointRCNN(num_classes=test_loader.dataset.num_class, use_xyz=True, mode='TEST')\n",
    "            model.cuda()\n",
    "\n",
    "            load_ckpt_based_on_args(model, logger)\n",
    "\n",
    "            detect_one_epoch_joint(model, test_loader, epoch_id, root_result_dir, logger, sample_token)\n",
    "            \n",
    "            \n",
    "        \n",
    "        # remove all the lidar_files and image files\n",
    "        files = glob.glob(lidar_folder + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "        files = glob.glob(image_folder + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "    \n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "        postprocessing\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    \n",
    "    kitti_id += 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
