{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../lib/')\n",
    "sys.path.append('../lib/net/')\n",
    "sys.path.append('../lib/rpn/')\n",
    "sys.path.append('../lib/utils/iou3d/')\n",
    "sys.path.append('../lib/utils/roipool3d/')\n",
    "sys.path.append('../lib/utils/roipool3d/build/')\n",
    "sys.path.append('../pointnet2_lib/')\n",
    "sys.path.append('../pointnet2_lib/')\n",
    "sys.path.append('../pointnet2_lib/pointnet2/')\n",
    "sys.path.append('../pointnet2_lib/tools/')\n",
    "sys.path.append('./train_utils/')\n",
    "sys.path.append('./kitti_object_eval_python/')\n",
    "sys.path.append('./cfgs/')\n",
    "\n",
    "import _init_path\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from lib.net.point_rcnn import PointRCNN\n",
    "from lib.datasets.kitti_rcnn_dataset import KittiRCNNDataset\n",
    "import tools.train_utils.train_utils as train_utils\n",
    "from lib.utils.bbox_transform import decode_bbox_target\n",
    "from tools.kitti_object_eval_python.evaluate import evaluate as kitti_evaluate\n",
    "\n",
    "from lib.config import cfg, cfg_from_file, save_config_to_file, cfg_from_list\n",
    "import argparse\n",
    "import lib.utils.kitti_utils as kitti_utils\n",
    "import lib.utils.iou3d.iou3d_utils as iou3d_utils\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "import json\n",
    "import math \n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import Tuple,List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import sklearn.metrics\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib import animation, rc\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as ts\n",
    "from plotly.offline import plot, init_notebook_mode\n",
    "import plotly.figure_factory as ft\n",
    "init_notebook_mode(connected=True)\n",
    "from pyquaternion import Quaternion\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from lyft_dataset_sdk.utils.map_mask import MapMask\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, box_in_image, BoxVisibility\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix\n",
    "from pathlib import Path\n",
    "\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset,LyftDatasetExplorer\n",
    "from lyft_dataset_sdk.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix\n",
    "import time\n",
    "from lyft_dataset_sdk.utils.map_mask import MapMask\n",
    "\n",
    "import struct\n",
    "from abc import ABC, abstractmethod\n",
    "from functools import reduce\n",
    "from typing import Tuple, List, Dict\n",
    "import copy\n",
    "from shutil import copyfile\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## args input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1024)  # set the same seed\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "args = edict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_class = 'car'\n",
    "\n",
    "args.ckpt = '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
    "\n",
    "args.output_dir = '../predicted/mirror'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.cfg_file = 'cfgs/' + saved_class + '.yaml'\n",
    "args.eval_mode = 'rcnn'\n",
    "\n",
    "\n",
    "args.eval_all = False\n",
    "args.test = True \n",
    "\n",
    "args.rpn_ckpt = None\n",
    "args.rcnn_ckpt = None\n",
    "\n",
    "\n",
    "args.batch_size = 4\n",
    "args.workers = 4\n",
    "args.extra_tag = 'default'\n",
    "args.ckpt_dir = None\n",
    "\n",
    "\n",
    "args.save_result = False\n",
    "args.save_rpn_feature = False\n",
    "\n",
    "\n",
    "args.random_select = True\n",
    "args.start_epoch = 0\n",
    "args.rcnn_eval_roi_dir = None\n",
    "args.rcnn_eval_feature_dir = None\n",
    "args.set_cfgs = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ling's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logger(log_file):\n",
    "    log_format = '%(asctime)s  %(levelname)5s  %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_format, filename=log_file)\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    console.setFormatter(logging.Formatter(log_format))\n",
    "    logging.getLogger(__name__).addHandler(console)\n",
    "    return logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(logger):\n",
    "    mode = 'TEST' \n",
    "    DATA_PATH = os.path.join('..', 'data')\n",
    "\n",
    "    # create dataloader\n",
    "    test_set = KittiRCNNDataset(root_dir=DATA_PATH, npoints=cfg.RPN.NUM_POINTS, split='test', mode=mode,\n",
    "                                random_select=args.random_select,\n",
    "                                rcnn_eval_roi_dir=args.rcnn_eval_roi_dir,\n",
    "                                rcnn_eval_feature_dir=args.rcnn_eval_feature_dir,\n",
    "                                classes=cfg.CLASSES,\n",
    "                                logger=logger)\n",
    "\n",
    "    test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, pin_memory=True,\n",
    "                             num_workers=args.workers, collate_fn=test_set.collate_batch)\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save_predicted_boxes3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predicted_boxes3d(pred_boxes3d, scores_pred, savefile):\n",
    "    \"\"\"\n",
    "        args:\n",
    "            pred_boxes3d: numpy.ndarray (ncars * 7[x, y, z, height, width, length, yaw])\n",
    "            \n",
    "            scores_pred: numpy.ndarray (ncars * 1)\n",
    "            \n",
    "            savefile: savefile name, save format: [confidence, x, y, z, width, length, height, yaw, classname]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    with open(savefile, 'w') as f:\n",
    "        for k in range(pred_boxes3d.shape[0]):\n",
    "            #print('%.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %s' %\n",
    "            #      (scores_pred[k], pred_boxes3d[k, 0], pred_boxes3d[k, 1], pred_boxes3d[k, 2], \n",
    "            #       pred_boxes3d[k, 4], pred_boxes3d[k, 5], pred_boxes3d[k, 3],pred_boxes3d[k, 6],\n",
    "            #      saved_class), file=f)\n",
    "            print('%.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %s' %\n",
    "                  (scores_pred[k], pred_boxes3d[k, 0], pred_boxes3d[k, 1], -pred_boxes3d[k, 2], \n",
    "                   pred_boxes3d[k, 4], pred_boxes3d[k, 5], pred_boxes3d[k, 3],3.142-pred_boxes3d[k, 6],\n",
    "                  saved_class), file=f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load_ckpt_based_on_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckpt_based_on_args(model, logger):\n",
    "    if args.ckpt is not None:\n",
    "        train_utils.load_checkpoint(model, filename=args.ckpt, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### detect_one_epoch_join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_one_epoch_joint(model, dataloader, epoch_id, result_dir, logger, sample_token):\n",
    "    '''\n",
    "    use joint (rpn + rcnn) model to detect object\n",
    "    \n",
    "    output:\n",
    "        predicted 3dboxes stored in result_dir\n",
    "    \n",
    "    '''\n",
    "    np.random.seed(666)\n",
    "    MEAN_SIZE = torch.from_numpy(cfg.CLS_MEAN_SIZE[0]).cuda()\n",
    "\n",
    "    predicted_boxes3d_dir = os.path.join(result_dir, 'pred_boxes3d', cfg.CLASSES)\n",
    "    os.makedirs(predicted_boxes3d_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    logger.info('---- EPOCH %s JOINT PREDICTION ----' % epoch_id)\n",
    "    logger.info('==> Output file: %s' % predicted_boxes3d_dir)\n",
    "    model.eval()\n",
    "\n",
    "    thresh_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    total_recalled_bbox_list, total_gt_bbox = [0] * 5, 0\n",
    "    total_roi_recalled_bbox_list = [0] * 5\n",
    "    dataset = dataloader.dataset\n",
    "    cnt = final_total = total_cls_acc = total_cls_acc_refined = total_rpn_iou = 0\n",
    "\n",
    "    progress_bar = tqdm.tqdm(total=len(dataloader), leave=True, desc='eval')\n",
    "    for data in dataloader:\n",
    "        cnt += 1\n",
    "        sample_id, pts_rect, pts_features, pts_input = \\\n",
    "            data['sample_id'], data['pts_rect'], data['pts_features'], data['pts_input']\n",
    "        batch_size = len(sample_id)\n",
    "        inputs = torch.from_numpy(pts_input).cuda(non_blocking=True).float()\n",
    "        input_data = {'pts_input': inputs}\n",
    "\n",
    "        # model inference\n",
    "        ret_dict = model(input_data)\n",
    "\n",
    "        roi_scores_raw = ret_dict['roi_scores_raw']  # (B, M)\n",
    "        roi_boxes3d = ret_dict['rois']  # (B, M, 7)\n",
    "        seg_result = ret_dict['seg_result'].long()  # (B, N)\n",
    "\n",
    "        rcnn_cls = ret_dict['rcnn_cls'].view(batch_size, -1, ret_dict['rcnn_cls'].shape[1])\n",
    "        rcnn_reg = ret_dict['rcnn_reg'].view(batch_size, -1, ret_dict['rcnn_reg'].shape[1])  # (B, M, C)\n",
    "\n",
    "        # bounding box regression\n",
    "        anchor_size = MEAN_SIZE\n",
    "        if cfg.RCNN.SIZE_RES_ON_ROI:\n",
    "            assert False\n",
    "\n",
    "        pred_boxes3d = decode_bbox_target(roi_boxes3d.view(-1, 7), rcnn_reg.view(-1, rcnn_reg.shape[-1]),\n",
    "                                          anchor_size=anchor_size,\n",
    "                                          loc_scope=cfg.RCNN.LOC_SCOPE,\n",
    "                                          loc_bin_size=cfg.RCNN.LOC_BIN_SIZE,\n",
    "                                          num_head_bin=cfg.RCNN.NUM_HEAD_BIN,\n",
    "                                          get_xz_fine=True, get_y_by_bin=cfg.RCNN.LOC_Y_BY_BIN,\n",
    "                                          loc_y_scope=cfg.RCNN.LOC_Y_SCOPE, loc_y_bin_size=cfg.RCNN.LOC_Y_BIN_SIZE,\n",
    "                                          get_ry_fine=True).view(batch_size, -1, 7)\n",
    "        \n",
    "        print(type(pred_boxes3d))\n",
    "\n",
    "        # scoring\n",
    "        if rcnn_cls.shape[2] == 1:\n",
    "            raw_scores = rcnn_cls  # (B, M, 1)\n",
    "\n",
    "            norm_scores = torch.sigmoid(raw_scores)\n",
    "            pred_classes = (norm_scores > cfg.RCNN.SCORE_THRESH).long()\n",
    "        else:\n",
    "            pred_classes = torch.argmax(rcnn_cls, dim=1).view(-1)\n",
    "            cls_norm_scores = F.softmax(rcnn_cls, dim=1)\n",
    "            raw_scores = rcnn_cls[:, pred_classes]\n",
    "            norm_scores = cls_norm_scores[:, pred_classes]\n",
    "            \n",
    "        \n",
    "        disp_dict = {'mode': 'Predicting'}\n",
    "        progress_bar.set_postfix(disp_dict)\n",
    "        progress_bar.update()\n",
    "\n",
    "        # scores thresh\n",
    "        inds = norm_scores > cfg.RCNN.SCORE_THRESH\n",
    "\n",
    "        for k in range(batch_size):\n",
    "            cur_inds = inds[k].view(-1)\n",
    "            if cur_inds.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            pred_boxes3d_selected = pred_boxes3d[k, cur_inds]\n",
    "            raw_scores_selected = raw_scores[k, cur_inds]\n",
    "            norm_scores_selected = norm_scores[k, cur_inds]\n",
    "            \n",
    "\n",
    "            # NMS thresh\n",
    "            # rotated nms\n",
    "            boxes_bev_selected = kitti_utils.boxes3d_to_bev_torch(pred_boxes3d_selected)\n",
    "            keep_idx = iou3d_utils.nms_gpu(boxes_bev_selected, raw_scores_selected, cfg.RCNN.NMS_THRESH).view(-1)\n",
    "            pred_boxes3d_selected = pred_boxes3d_selected[keep_idx]\n",
    "            scores_selected = raw_scores_selected[keep_idx]\n",
    "            pred_boxes3d_selected, scores_selected = pred_boxes3d_selected.cpu().numpy(), scores_selected.cpu().numpy()\n",
    "\n",
    "            cur_sample_id = sample_id[k]\n",
    "            savefile = os.path.join(predicted_boxes3d_dir, '%06d.txt' % cur_sample_id)\n",
    "            \n",
    "            save_predicted_boxes3d(pred_boxes3d_selected, norm_scores_selected, savefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tong's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### link folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link 'images/test_images': File exists\n",
      "ln: failed to create symbolic link 'maps/test_maps': File exists\n",
      "ln: failed to create symbolic link 'lidar/test_lidar': File exists\n"
     ]
    }
   ],
   "source": [
    "!ln -s ../../3d-object-detection-for-autonomous-vehicles/test_images images\n",
    "!ln -s ../../3d-object-detection-for-autonomous-vehicles/test_maps maps\n",
    "!ln -s ../../3d-object-detection-for-autonomous-vehicles/test_lidar lidar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file instance.json missing, using empty list\n",
      "JSON file sample_annotation.json missing, using empty list\n",
      "9 category,\n",
      "17 attribute,\n",
      "4 visibility,\n",
      "0 instance,\n",
      "8 sensor,\n",
      "168 calibrated_sensor,\n",
      "219744 ego_pose,\n",
      "218 log,\n",
      "218 scene,\n",
      "27468 sample,\n",
      "219744 sample_data,\n",
      "0 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 1.9 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.7 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "test_dataset = LyftDataset(data_path='.', json_path='../../3d-object-detection-for-autonomous-vehicles/test_data', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output transformation: global_from_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_global_from_rect(sample_ID,args):\n",
    "    #args = [x,y,z,width,length,height,yaw]\n",
    "    # get the label from the sample_ID\n",
    "    import math\n",
    "    sample_token=sample_ID \n",
    "    sample = test_dataset.get(\"sample\", sample_token)\n",
    "\n",
    "    sample_lidar_token = sample[\"data\"][\"LIDAR_TOP\"]\n",
    "    lidar_data = test_dataset.get(\"sample_data\", sample_lidar_token)\n",
    "\n",
    "    # get lidar calibration info\n",
    "    ego_pose = test_dataset.get(\"ego_pose\", lidar_data[\"ego_pose_token\"])\n",
    "    calibrated_sensor = test_dataset.get(\"calibrated_sensor\", lidar_data[\"calibrated_sensor_token\"])\n",
    "\n",
    "    # get the transformation matrix from calibration info\n",
    "    Tr_rect_sensor = np.array([[-1,0,0,0],[0,0,1,0],[0,-1,0,0],[0,0,0,1]])\n",
    "\n",
    "    global_from_car = transform_matrix(ego_pose['translation'],\n",
    "                                       Quaternion(ego_pose['rotation']), inverse=False)\n",
    "    car_from_sensor = transform_matrix(calibrated_sensor['translation'], Quaternion(calibrated_sensor['rotation']),\n",
    "                                        inverse=False)\n",
    "    global_from_sensor = np.dot(global_from_car,car_from_sensor)\n",
    "    \n",
    "    global_from_rect = np.dot(global_from_sensor,Tr_rect_sensor)\n",
    "    \n",
    "    center_x = args[0]\n",
    "    center_y = args[1]\n",
    "    center_z = args[2]\n",
    "    width = args[3]\n",
    "    length = args[4]\n",
    "    height = args[5]\n",
    "    yaw = args[6]\n",
    "        \n",
    "        \n",
    "        \n",
    "    # transfrom the center point from global to sensor (center_x,center_y,center_z)->(x,y,z)\n",
    "    tmp = np.array([[center_x],[center_y],[center_z],[1.0]])\n",
    "    coor = np.dot(global_from_rect,tmp)\n",
    "    x = coor[0][0]\n",
    "    y = coor[1][0]\n",
    "    z = coor[2][0]\n",
    "\n",
    "    # transform the yaw from sensor to global yaw->yaw_sensor\n",
    "    # yaw vector += center vector\n",
    "    x_yaw = center_x - np.sin(yaw)\n",
    "    z_yaw = center_z + np.cos(yaw)\n",
    "    y_yaw = center_y\n",
    "    # transfer yaw vector to sensor\n",
    "    coor_yaw = np.dot(global_from_rect,np.array([[x_yaw],[y_yaw],[z_yaw],[1.0]]))\n",
    "    x_yaw_global = coor_yaw[0][0]\n",
    "    y_yaw_global = coor_yaw[1][0]\n",
    "    z_yaw_global = coor_yaw[2][0]\n",
    "    # the angle between yaw_sensor and the y axis\n",
    "    #yaw_new = np.arccos(np.clip(np.dot((1,0),(y_yaw_global - y,x_yaw_global - x)), -1.0, 1.0))\n",
    "    yaw_new = math.atan2(-(x_yaw_global - x),y_yaw_global - y)\n",
    "    \n",
    "        \n",
    "    return [x,y,z,width,length,height,yaw_new]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lidar_filepath_from_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lidar_filepath_from_id(sample_token):\n",
    "    sample = test_dataset.get(\"sample\", sample_token)\n",
    "\n",
    "    sample_lidar_token = sample[\"data\"][\"LIDAR_TOP\"]\n",
    "    \n",
    "    lidar_path = test_dataset.get_sample_data_path(sample_lidar_token)\n",
    "    return lidar_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write_image_from_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image_from_id(image_folder,kitti_id,sample_token):\n",
    "    \n",
    "\n",
    "    sample = test_dataset.get(\"sample\", sample_token)\n",
    "\n",
    "    sample_cam_token = sample[\"data\"][\"CAM_FRONT_LEFT\"]\n",
    "    cam_data = test_dataset.get(\"sample_data\", sample_cam_token)\n",
    "    cam_filepath = test_dataset.get_sample_data_path(sample_cam_token)\n",
    "    \n",
    "    im = Image.open(cam_filepath)\n",
    "    im.save(os.path.join(image_folder,\"{:06n}\".format(kitti_id)+\".png\"), \"PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calib file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_calib(calib_folder,idx):\n",
    "    \n",
    "    label_save_fn = os.path.join(calib_folder,\"{:06n}\".format(idx)+'.txt')\n",
    "    Tr_lyft_rect = np.array([-1,  0,  0,  0, 0,  0, -1,  0, 0,  1,  0,  0])\n",
    "    R0_rect = np.array([1,0,0,0,1,0,0,0,1])\n",
    "    with open(label_save_fn, 'w') as f:\n",
    "\n",
    "        print('P0: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f'  %\n",
    "                          (1,0,0,0,0,1,0,0,0,0,1,0),file=f)\n",
    "        print('P1: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f'  %\n",
    "                          (1,0,0,0,0,1,0,0,0,0,1,0),file=f)\n",
    "        print('P2: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f'  %\n",
    "                          (1,0,0,0,0,1,0,0,0,0,1,0),file=f)\n",
    "        print('P3: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f'  %\n",
    "                          (1,0,0,0,0,1,0,0,0,0,1,0),file=f)\n",
    "\n",
    "        print('R0_rect: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f' %\n",
    "                          (R0_rect[0], R0_rect[1],R0_rect[2], R0_rect[3], R0_rect[4],\n",
    "                           R0_rect[5], R0_rect[6], R0_rect[7], R0_rect[8]),file=f)\n",
    "\n",
    "        #print('Tr_velo_to_cam: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f' %\n",
    "        #                  (-1,0,0,0,0,0,-1,0,0,1,0,0),file=f)\n",
    "        # z= -z\n",
    "        print('Tr_velo_to_cam: %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f' %\n",
    "                          (-1,0,0,0,0,0,-1,0,0,-1,0,0),file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingling/Downloads/Lyft_PointRCNN/tools/../lib/config.py:187: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n",
      "2019-11-12 16:50:02,927   INFO  **********************Start logging**********************\n",
      "2019-11-12 16:50:02,928   INFO  ckpt             ../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth\n",
      "2019-11-12 16:50:02,928   INFO  output_dir       ../predicted/mirror\n",
      "2019-11-12 16:50:02,929   INFO  cfg_file         cfgs/car.yaml\n",
      "2019-11-12 16:50:02,929   INFO  eval_mode        rcnn\n",
      "2019-11-12 16:50:02,929   INFO  eval_all         False\n",
      "2019-11-12 16:50:02,930   INFO  test             True\n",
      "2019-11-12 16:50:02,930   INFO  rpn_ckpt         None\n",
      "2019-11-12 16:50:02,931   INFO  rcnn_ckpt        None\n",
      "2019-11-12 16:50:02,931   INFO  batch_size       4\n",
      "2019-11-12 16:50:02,931   INFO  workers          4\n",
      "2019-11-12 16:50:02,931   INFO  extra_tag        default\n",
      "2019-11-12 16:50:02,932   INFO  ckpt_dir         None\n",
      "2019-11-12 16:50:02,932   INFO  save_result      False\n",
      "2019-11-12 16:50:02,932   INFO  save_rpn_feature False\n",
      "2019-11-12 16:50:02,932   INFO  random_select    True\n",
      "2019-11-12 16:50:02,933   INFO  start_epoch      0\n",
      "2019-11-12 16:50:02,933   INFO  rcnn_eval_roi_dir None\n",
      "2019-11-12 16:50:02,933   INFO  rcnn_eval_feature_dir None\n",
      "2019-11-12 16:50:02,933   INFO  set_cfgs         None\n",
      "2019-11-12 16:50:02,934   INFO  cfg.TAG: car\n",
      "2019-11-12 16:50:02,934   INFO  cfg.CLASSES: Car\n",
      "2019-11-12 16:50:02,934   INFO  cfg.INCLUDE_SIMILAR_TYPE: True\n",
      "2019-11-12 16:50:02,935   INFO  cfg.AUG_DATA: False\n",
      "2019-11-12 16:50:02,935   INFO  cfg.AUG_METHOD_LIST: ['rotation', 'scaling', 'flip']\n",
      "2019-11-12 16:50:02,935   INFO  cfg.AUG_METHOD_PROB: [1.0, 1.0, 0.5]\n",
      "2019-11-12 16:50:02,935   INFO  cfg.AUG_ROT_RANGE: 18\n",
      "2019-11-12 16:50:02,936   INFO  cfg.GT_AUG_ENABLED: False\n",
      "2019-11-12 16:50:02,937   INFO  cfg.GT_EXTRA_NUM: 15\n",
      "2019-11-12 16:50:02,937   INFO  cfg.GT_AUG_RAND_NUM: True\n",
      "2019-11-12 16:50:02,938   INFO  cfg.GT_AUG_APPLY_PROB: 1.0\n",
      "2019-11-12 16:50:02,938   INFO  cfg.GT_AUG_HARD_RATIO: 0.6\n",
      "2019-11-12 16:50:02,938   INFO  cfg.PC_REDUCE_BY_RANGE: True\n",
      "2019-11-12 16:50:02,939   INFO  cfg.PC_AREA_SCOPE: [[-70.   70. ]\n",
      " [ -1.    3. ]\n",
      " [-70.4  70.4]]\n",
      "2019-11-12 16:50:02,939   INFO  cfg.CLS_MEAN_SIZE: [[1.5256319 1.6285675 3.8831165]]\n",
      "2019-11-12 16:50:02,939   INFO  \n",
      "cfg.RPN = edict()\n",
      "2019-11-12 16:50:02,940   INFO  cfg.RPN.ENABLED: True\n",
      "2019-11-12 16:50:02,940   INFO  cfg.RPN.FIXED: True\n",
      "2019-11-12 16:50:02,940   INFO  cfg.RPN.USE_INTENSITY: False\n",
      "2019-11-12 16:50:02,940   INFO  cfg.RPN.LOC_XZ_FINE: True\n",
      "2019-11-12 16:50:02,941   INFO  cfg.RPN.LOC_SCOPE: 3.0\n",
      "2019-11-12 16:50:02,941   INFO  cfg.RPN.LOC_BIN_SIZE: 0.5\n",
      "2019-11-12 16:50:02,941   INFO  cfg.RPN.NUM_HEAD_BIN: 12\n",
      "2019-11-12 16:50:02,943   INFO  cfg.RPN.BACKBONE: pointnet2_msg\n",
      "2019-11-12 16:50:02,943   INFO  cfg.RPN.USE_BN: True\n",
      "2019-11-12 16:50:02,943   INFO  cfg.RPN.NUM_POINTS: 16384\n",
      "2019-11-12 16:50:02,943   INFO  \n",
      "cfg.RPN.SA_CONFIG = edict()\n",
      "2019-11-12 16:50:02,944   INFO  cfg.RPN.SA_CONFIG.NPOINTS: [4096, 1024, 256, 64]\n",
      "2019-11-12 16:50:02,944   INFO  cfg.RPN.SA_CONFIG.RADIUS: [[0.1, 0.5], [0.5, 1.0], [1.0, 2.0], [2.0, 4.0]]\n",
      "2019-11-12 16:50:02,944   INFO  cfg.RPN.SA_CONFIG.NSAMPLE: [[16, 32], [16, 32], [16, 32], [16, 32]]\n",
      "2019-11-12 16:50:02,944   INFO  cfg.RPN.SA_CONFIG.MLPS: [[[16, 16, 32], [32, 32, 64]], [[64, 64, 128], [64, 96, 128]], [[128, 196, 256], [128, 196, 256]], [[256, 256, 512], [256, 384, 512]]]\n",
      "2019-11-12 16:50:02,945   INFO  cfg.RPN.FP_MLPS: [[128, 128], [256, 256], [512, 512], [512, 512]]\n",
      "2019-11-12 16:50:02,945   INFO  cfg.RPN.CLS_FC: [128]\n",
      "2019-11-12 16:50:02,945   INFO  cfg.RPN.REG_FC: [128]\n",
      "2019-11-12 16:50:02,945   INFO  cfg.RPN.DP_RATIO: 0.5\n",
      "2019-11-12 16:50:02,946   INFO  cfg.RPN.LOSS_CLS: SigmoidFocalLoss\n",
      "2019-11-12 16:50:02,946   INFO  cfg.RPN.FG_WEIGHT: 15\n",
      "2019-11-12 16:50:02,946   INFO  cfg.RPN.FOCAL_ALPHA: [0.25, 0.75]\n",
      "2019-11-12 16:50:02,946   INFO  cfg.RPN.FOCAL_GAMMA: 2.0\n",
      "2019-11-12 16:50:02,947   INFO  cfg.RPN.REG_LOSS_WEIGHT: [1.0, 1.0, 1.0, 1.0]\n",
      "2019-11-12 16:50:02,947   INFO  cfg.RPN.LOSS_WEIGHT: [1.0, 1.0]\n",
      "2019-11-12 16:50:02,947   INFO  cfg.RPN.NMS_TYPE: normal\n",
      "2019-11-12 16:50:02,947   INFO  cfg.RPN.SCORE_THRESH: 0.3\n",
      "2019-11-12 16:50:02,949   INFO  \n",
      "cfg.RCNN = edict()\n",
      "2019-11-12 16:50:02,949   INFO  cfg.RCNN.ENABLED: True\n",
      "2019-11-12 16:50:02,949   INFO  cfg.RCNN.USE_RPN_FEATURES: True\n",
      "2019-11-12 16:50:02,950   INFO  cfg.RCNN.USE_MASK: True\n",
      "2019-11-12 16:50:02,950   INFO  cfg.RCNN.MASK_TYPE: seg\n",
      "2019-11-12 16:50:02,950   INFO  cfg.RCNN.USE_INTENSITY: False\n",
      "2019-11-12 16:50:02,951   INFO  cfg.RCNN.USE_DEPTH: True\n",
      "2019-11-12 16:50:02,951   INFO  cfg.RCNN.USE_SEG_SCORE: False\n",
      "2019-11-12 16:50:02,951   INFO  cfg.RCNN.ROI_SAMPLE_JIT: True\n",
      "2019-11-12 16:50:02,951   INFO  cfg.RCNN.ROI_FG_AUG_TIMES: 10\n",
      "2019-11-12 16:50:02,952   INFO  cfg.RCNN.REG_AUG_METHOD: multiple\n",
      "2019-11-12 16:50:02,952   INFO  cfg.RCNN.POOL_EXTRA_WIDTH: 1.0\n",
      "2019-11-12 16:50:02,952   INFO  cfg.RCNN.LOC_SCOPE: 1.5\n",
      "2019-11-12 16:50:02,952   INFO  cfg.RCNN.LOC_BIN_SIZE: 0.5\n",
      "2019-11-12 16:50:02,953   INFO  cfg.RCNN.NUM_HEAD_BIN: 9\n",
      "2019-11-12 16:50:02,953   INFO  cfg.RCNN.LOC_Y_BY_BIN: False\n",
      "2019-11-12 16:50:02,953   INFO  cfg.RCNN.LOC_Y_SCOPE: 0.5\n",
      "2019-11-12 16:50:02,953   INFO  cfg.RCNN.LOC_Y_BIN_SIZE: 0.25\n",
      "2019-11-12 16:50:02,954   INFO  cfg.RCNN.SIZE_RES_ON_ROI: False\n",
      "2019-11-12 16:50:02,955   INFO  cfg.RCNN.USE_BN: False\n",
      "2019-11-12 16:50:02,955   INFO  cfg.RCNN.DP_RATIO: 0.0\n",
      "2019-11-12 16:50:02,955   INFO  cfg.RCNN.BACKBONE: pointnet\n",
      "2019-11-12 16:50:02,955   INFO  cfg.RCNN.XYZ_UP_LAYER: [128, 128]\n",
      "2019-11-12 16:50:02,956   INFO  cfg.RCNN.NUM_POINTS: 512\n",
      "2019-11-12 16:50:02,956   INFO  \n",
      "cfg.RCNN.SA_CONFIG = edict()\n",
      "2019-11-12 16:50:02,956   INFO  cfg.RCNN.SA_CONFIG.NPOINTS: [128, 32, -1]\n",
      "2019-11-12 16:50:02,957   INFO  cfg.RCNN.SA_CONFIG.RADIUS: [0.2, 0.4, 100]\n",
      "2019-11-12 16:50:02,957   INFO  cfg.RCNN.SA_CONFIG.NSAMPLE: [64, 64, 64]\n",
      "2019-11-12 16:50:02,957   INFO  cfg.RCNN.SA_CONFIG.MLPS: [[128, 128, 128], [128, 128, 256], [256, 256, 512]]\n",
      "2019-11-12 16:50:02,958   INFO  cfg.RCNN.CLS_FC: [256, 256]\n",
      "2019-11-12 16:50:02,958   INFO  cfg.RCNN.REG_FC: [256, 256]\n",
      "2019-11-12 16:50:02,958   INFO  cfg.RCNN.LOSS_CLS: BinaryCrossEntropy\n",
      "2019-11-12 16:50:02,959   INFO  cfg.RCNN.FOCAL_ALPHA: [0.25, 0.75]\n",
      "2019-11-12 16:50:02,959   INFO  cfg.RCNN.FOCAL_GAMMA: 2.0\n",
      "2019-11-12 16:50:02,959   INFO  cfg.RCNN.CLS_WEIGHT: [1. 1. 1.]\n",
      "2019-11-12 16:50:02,960   INFO  cfg.RCNN.CLS_FG_THRESH: 0.6\n",
      "2019-11-12 16:50:02,960   INFO  cfg.RCNN.CLS_BG_THRESH: 0.45\n",
      "2019-11-12 16:50:02,961   INFO  cfg.RCNN.CLS_BG_THRESH_LO: 0.05\n",
      "2019-11-12 16:50:02,961   INFO  cfg.RCNN.REG_FG_THRESH: 0.55\n",
      "2019-11-12 16:50:02,961   INFO  cfg.RCNN.FG_RATIO: 0.5\n",
      "2019-11-12 16:50:02,961   INFO  cfg.RCNN.ROI_PER_IMAGE: 64\n",
      "2019-11-12 16:50:02,962   INFO  cfg.RCNN.HARD_BG_RATIO: 0.8\n",
      "2019-11-12 16:50:02,962   INFO  cfg.RCNN.SCORE_THRESH: 0.15\n",
      "2019-11-12 16:50:02,962   INFO  cfg.RCNN.NMS_THRESH: 0.05\n",
      "2019-11-12 16:50:02,962   INFO  \n",
      "cfg.TRAIN = edict()\n",
      "2019-11-12 16:50:02,962   INFO  cfg.TRAIN.SPLIT: train\n",
      "2019-11-12 16:50:02,963   INFO  cfg.TRAIN.VAL_SPLIT: smallval\n",
      "2019-11-12 16:50:02,963   INFO  cfg.TRAIN.LR: 0.002\n",
      "2019-11-12 16:50:02,963   INFO  cfg.TRAIN.LR_CLIP: 1e-05\n",
      "2019-11-12 16:50:02,964   INFO  cfg.TRAIN.LR_DECAY: 0.5\n",
      "2019-11-12 16:50:02,964   INFO  cfg.TRAIN.DECAY_STEP_LIST: [100, 150, 180, 200]\n",
      "2019-11-12 16:50:02,965   INFO  cfg.TRAIN.LR_WARMUP: True\n",
      "2019-11-12 16:50:02,965   INFO  cfg.TRAIN.WARMUP_MIN: 0.0002\n",
      "2019-11-12 16:50:02,965   INFO  cfg.TRAIN.WARMUP_EPOCH: 1\n",
      "2019-11-12 16:50:02,965   INFO  cfg.TRAIN.BN_MOMENTUM: 0.1\n",
      "2019-11-12 16:50:02,966   INFO  cfg.TRAIN.BN_DECAY: 0.5\n",
      "2019-11-12 16:50:02,966   INFO  cfg.TRAIN.BNM_CLIP: 0.01\n",
      "2019-11-12 16:50:02,966   INFO  cfg.TRAIN.BN_DECAY_STEP_LIST: [1000]\n",
      "2019-11-12 16:50:02,966   INFO  cfg.TRAIN.OPTIMIZER: adam_onecycle\n",
      "2019-11-12 16:50:02,967   INFO  cfg.TRAIN.WEIGHT_DECAY: 0.001\n",
      "2019-11-12 16:50:02,967   INFO  cfg.TRAIN.MOMENTUM: 0.9\n",
      "2019-11-12 16:50:02,967   INFO  cfg.TRAIN.MOMS: [0.95, 0.85]\n",
      "2019-11-12 16:50:02,967   INFO  cfg.TRAIN.DIV_FACTOR: 10.0\n",
      "2019-11-12 16:50:02,968   INFO  cfg.TRAIN.PCT_START: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 16:50:02,968   INFO  cfg.TRAIN.GRAD_NORM_CLIP: 1.0\n",
      "2019-11-12 16:50:02,968   INFO  cfg.TRAIN.RPN_PRE_NMS_TOP_N: 9000\n",
      "2019-11-12 16:50:02,968   INFO  cfg.TRAIN.RPN_POST_NMS_TOP_N: 512\n",
      "2019-11-12 16:50:02,969   INFO  cfg.TRAIN.RPN_NMS_THRESH: 0.85\n",
      "2019-11-12 16:50:02,969   INFO  cfg.TRAIN.RPN_DISTANCE_BASED_PROPOSE: True\n",
      "2019-11-12 16:50:02,969   INFO  \n",
      "cfg.TEST = edict()\n",
      "2019-11-12 16:50:02,969   INFO  cfg.TEST.SPLIT: val\n",
      "2019-11-12 16:50:02,970   INFO  cfg.TEST.RPN_PRE_NMS_TOP_N: 9000\n",
      "2019-11-12 16:50:02,970   INFO  cfg.TEST.RPN_POST_NMS_TOP_N: 100\n",
      "2019-11-12 16:50:02,970   INFO  cfg.TEST.RPN_NMS_THRESH: 0.8\n",
      "2019-11-12 16:50:02,970   INFO  cfg.TEST.RPN_DISTANCE_BASED_PROPOSE: True\n"
     ]
    }
   ],
   "source": [
    "# merge config and log to file\n",
    "if args.cfg_file is not None:\n",
    "    cfg_from_file(args.cfg_file)\n",
    "       \n",
    "cfg.TAG = os.path.splitext(os.path.basename(args.cfg_file))[0]\n",
    "\n",
    "\n",
    "# args.eval_mode == 'rcnn':\n",
    "cfg.RCNN.ENABLED = True\n",
    "cfg.RPN.ENABLED = cfg.RPN.FIXED = True\n",
    "root_result_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG)\n",
    "ckpt_dir = args.ckpt_dir\n",
    "\n",
    "if args.output_dir is not None:\n",
    "    root_result_dir = args.output_dir\n",
    "    \n",
    " # set epoch_id and output dir\n",
    "num_list = re.findall(r'\\d+', args.ckpt) if args.ckpt is not None else []\n",
    "epoch_id = num_list[-1] if num_list.__len__() > 0 else 'no_number'\n",
    "root_result_dir = os.path.join(root_result_dir, 'epoch_%s' % epoch_id)\n",
    "\n",
    "os.makedirs(root_result_dir, exist_ok=True)\n",
    "\n",
    "log_file = os.path.join(root_result_dir, 'log_eval_one.txt')\n",
    "logger = create_logger(log_file)\n",
    "logger.info('**********************Start logging**********************')\n",
    "for key, val in vars(args).items():\n",
    "    logger.info(\"{:16} {}\".format(key, val))\n",
    "save_config_to_file(cfg, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 16:50:04,413   INFO  Load testing samples from ../data/KITTI/object/testing\n",
      "2019-11-12 16:50:04,414   INFO  Done: total test samples 17\n",
      "2019-11-12 16:50:06,366   INFO  ==> Loading from checkpoint '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
      "2019-11-12 16:50:06,396   INFO  ==> Done\n",
      "2019-11-12 16:50:06,397   INFO  ---- EPOCH 2 JOINT PREDICTION ----\n",
      "2019-11-12 16:50:06,397   INFO  ==> Output file: ../predicted/mirror/epoch_2/pred_boxes3d/Car\n",
      "eval:  20%|██        | 1/5 [00:00<00:02,  1.42it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval:  40%|████      | 2/5 [00:01<00:01,  1.68it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval:  60%|██████    | 3/5 [00:01<00:01,  1.93it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 5/5 [00:01<00:00,  2.65it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-11-12 16:50:10,256   INFO  Load testing samples from ../data/KITTI/object/testing\n",
      "2019-11-12 16:50:10,257   INFO  Done: total test samples 10\n",
      "2019-11-12 16:50:10,312   INFO  ==> Loading from checkpoint '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
      "2019-11-12 16:50:10,339   INFO  ==> Done\n",
      "2019-11-12 16:50:10,340   INFO  ---- EPOCH 2 JOINT PREDICTION ----\n",
      "2019-11-12 16:50:10,340   INFO  ==> Output file: ../predicted/mirror/epoch_2/pred_boxes3d/Car\n",
      "eval:  33%|███▎      | 1/3 [00:00<00:01,  1.95it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.62it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.75it/s, mode=Predicting]\n",
      "2019-11-12 16:50:13,492   INFO  Load testing samples from ../data/KITTI/object/testing\n",
      "2019-11-12 16:50:13,492   INFO  Done: total test samples 10\n",
      "2019-11-12 16:50:13,548   INFO  ==> Loading from checkpoint '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
      "2019-11-12 16:50:13,575   INFO  ==> Done\n",
      "2019-11-12 16:50:13,576   INFO  ---- EPOCH 2 JOINT PREDICTION ----\n",
      "2019-11-12 16:50:13,576   INFO  ==> Output file: ../predicted/mirror/epoch_2/pred_boxes3d/Car\n",
      "eval:  33%|███▎      | 1/3 [00:00<00:01,  1.94it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.61it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.74it/s, mode=Predicting]\n",
      "2019-11-12 16:50:16,744   INFO  Load testing samples from ../data/KITTI/object/testing\n",
      "2019-11-12 16:50:16,745   INFO  Done: total test samples 10\n",
      "2019-11-12 16:50:16,801   INFO  ==> Loading from checkpoint '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
      "2019-11-12 16:50:16,828   INFO  ==> Done\n",
      "2019-11-12 16:50:16,829   INFO  ---- EPOCH 2 JOINT PREDICTION ----\n",
      "2019-11-12 16:50:16,830   INFO  ==> Output file: ../predicted/mirror/epoch_2/pred_boxes3d/Car\n",
      "eval:  33%|███▎      | 1/3 [00:00<00:01,  1.97it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.63it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.76it/s, mode=Predicting]\n",
      "2019-11-12 16:50:19,912   INFO  Load testing samples from ../data/KITTI/object/testing\n",
      "2019-11-12 16:50:19,913   INFO  Done: total test samples 10\n",
      "2019-11-12 16:50:19,969   INFO  ==> Loading from checkpoint '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
      "2019-11-12 16:50:19,996   INFO  ==> Done\n",
      "2019-11-12 16:50:19,997   INFO  ---- EPOCH 2 JOINT PREDICTION ----\n",
      "2019-11-12 16:50:19,997   INFO  ==> Output file: ../predicted/mirror/epoch_2/pred_boxes3d/Car\n",
      "eval:  33%|███▎      | 1/3 [00:00<00:01,  1.95it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.62it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.74it/s, mode=Predicting]\n",
      "2019-11-12 16:50:23,104   INFO  Load testing samples from ../data/KITTI/object/testing\n",
      "2019-11-12 16:50:23,105   INFO  Done: total test samples 10\n",
      "2019-11-12 16:50:23,161   INFO  ==> Loading from checkpoint '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
      "2019-11-12 16:50:23,188   INFO  ==> Done\n",
      "2019-11-12 16:50:23,189   INFO  ---- EPOCH 2 JOINT PREDICTION ----\n",
      "2019-11-12 16:50:23,189   INFO  ==> Output file: ../predicted/mirror/epoch_2/pred_boxes3d/Car\n",
      "eval:  33%|███▎      | 1/3 [00:00<00:01,  1.93it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.60it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.73it/s, mode=Predicting]\n",
      "2019-11-12 16:50:26,470   INFO  Load testing samples from ../data/KITTI/object/testing\n",
      "2019-11-12 16:50:26,471   INFO  Done: total test samples 10\n",
      "2019-11-12 16:50:26,527   INFO  ==> Loading from checkpoint '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
      "2019-11-12 16:50:26,554   INFO  ==> Done\n",
      "2019-11-12 16:50:26,555   INFO  ---- EPOCH 2 JOINT PREDICTION ----\n",
      "2019-11-12 16:50:26,555   INFO  ==> Output file: ../predicted/mirror/epoch_2/pred_boxes3d/Car\n",
      "eval:  33%|███▎      | 1/3 [00:00<00:01,  1.99it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.66it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.78it/s, mode=Predicting]\n",
      "2019-11-12 16:50:29,658   INFO  Load testing samples from ../data/KITTI/object/testing\n",
      "2019-11-12 16:50:29,659   INFO  Done: total test samples 10\n",
      "2019-11-12 16:50:29,715   INFO  ==> Loading from checkpoint '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
      "2019-11-12 16:50:29,742   INFO  ==> Done\n",
      "2019-11-12 16:50:29,743   INFO  ---- EPOCH 2 JOINT PREDICTION ----\n",
      "2019-11-12 16:50:29,743   INFO  ==> Output file: ../predicted/mirror/epoch_2/pred_boxes3d/Car\n",
      "eval:  33%|███▎      | 1/3 [00:00<00:01,  1.97it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.64it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.76it/s, mode=Predicting]\n",
      "2019-11-12 16:50:32,787   INFO  Load testing samples from ../data/KITTI/object/testing\n",
      "2019-11-12 16:50:32,787   INFO  Done: total test samples 10\n",
      "2019-11-12 16:50:32,843   INFO  ==> Loading from checkpoint '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
      "2019-11-12 16:50:32,870   INFO  ==> Done\n",
      "2019-11-12 16:50:32,871   INFO  ---- EPOCH 2 JOINT PREDICTION ----\n",
      "2019-11-12 16:50:32,871   INFO  ==> Output file: ../predicted/mirror/epoch_2/pred_boxes3d/Car\n",
      "eval:  33%|███▎      | 1/3 [00:00<00:01,  1.94it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.61it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.74it/s, mode=Predicting]\n",
      "2019-11-12 16:50:36,058   INFO  Load testing samples from ../data/KITTI/object/testing\n",
      "2019-11-12 16:50:36,059   INFO  Done: total test samples 10\n",
      "2019-11-12 16:50:36,115   INFO  ==> Loading from checkpoint '../trainedModel/car/rcnn/ckpt/rpn30/checkpoint_epoch_2.pth'\n",
      "2019-11-12 16:50:36,141   INFO  ==> Done\n",
      "2019-11-12 16:50:36,142   INFO  ---- EPOCH 2 JOINT PREDICTION ----\n",
      "2019-11-12 16:50:36,143   INFO  ==> Output file: ../predicted/mirror/epoch_2/pred_boxes3d/Car\n",
      "eval:  33%|███▎      | 1/3 [00:00<00:01,  1.96it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.63it/s, mode=Predicting]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 3/3 [00:01<00:00,  2.75it/s, mode=Predicting]\n"
     ]
    }
   ],
   "source": [
    "calib_folder = \"/home/lingling/Downloads/Lyft_PointRCNN/data/KITTI/object/testing/calib/\"\n",
    "lidar_folder = '/home/lingling/Downloads/Lyft_PointRCNN/data/KITTI/object/testing/velodyne'\n",
    "image_folder = '/home/lingling/Downloads/Lyft_PointRCNN/data/KITTI/object/testing/image_2'\n",
    "testtxtfile = '/home/lingling/Downloads/Lyft_PointRCNN/data/KITTI/ImageSets/test.txt'\n",
    "\n",
    "os.makedirs(calib_folder, exist_ok=True)\n",
    "os.makedirs(lidar_folder, exist_ok=True)\n",
    "os.makedirs(image_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "#os.makedirs(lidar_folder)\n",
    "\n",
    "df = pd.read_csv('sample_submission.csv')\n",
    "lyfttest_Id = df['Id']\n",
    "\n",
    "\n",
    "kitti_id = 7373\n",
    "while(kitti_id < len(lyfttest_Id)):\n",
    "    \n",
    "    sample_token = lyfttest_Id[kitti_id]\n",
    "    \"\"\"\n",
    "        prepare test.txt, calibration file and the lidar files\n",
    "    \"\"\"\n",
    "    # write test.txt\n",
    "    if kitti_id % 10 == 0:\n",
    "        with open(testtxtfile, 'w') as f:\n",
    "            print(\"{:06n}\".format(kitti_id),file=f)\n",
    "    else:\n",
    "        with open(testtxtfile, 'a') as f:\n",
    "            print(\"{:06n}\".format(kitti_id),file=f)\n",
    "    \n",
    "    # write calibration file\n",
    "    write_calib(calib_folder,kitti_id)\n",
    "    \n",
    "    # extract lidar file path\n",
    "    lidar_filepath = lidar_filepath_from_id(sample_token)\n",
    "    # move lidar to path\n",
    "    lidar_savefilename = \"{:06n}\".format(kitti_id)+'.bin'\n",
    "    copyfile(lidar_filepath,os.path.join(lidar_folder, lidar_savefilename)) \n",
    "    # write image\n",
    "    write_image_from_id(image_folder,kitti_id,sample_token)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "        prediction part\n",
    "    \"\"\"\n",
    "    # predict every 10 files or at the last file\n",
    "    if kitti_id %10 == 9 or kitti_id ==  len(lyfttest_Id) -1:\n",
    "        # predition - arges\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # create dataloader & network\n",
    "            test_loader = create_dataloader(logger)\n",
    "            model = PointRCNN(num_classes=test_loader.dataset.num_class, use_xyz=True, mode='TEST')\n",
    "            model.cuda()\n",
    "\n",
    "            load_ckpt_based_on_args(model, logger)\n",
    "\n",
    "            detect_one_epoch_joint(model, test_loader, epoch_id, root_result_dir, logger, sample_token)\n",
    "            \n",
    "            \n",
    "        \n",
    "        # remove all the lidar_files and image files\n",
    "        files = glob.glob(lidar_folder + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "        files = glob.glob(image_folder + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "    \n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "        postprocessing\n",
    "    \"\"\"\n",
    "    \n",
    "#     #label = label_global_from_rect(sample_token,args)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    kitti_id += 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
